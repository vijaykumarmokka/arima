import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Statistical and Time Series Libraries
from scipy import stats
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split, cross_val_score
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.vector_ar.vecm import coint_johansen, select_order, VECM
from statsmodels.tsa.vector_ar.var_model import VAR

# Visualization Libraries
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo

class SimplifiedEnhancedSoybeanAnalysis:
    """
    Simplified Enhanced Comprehensive Soybean Market Analysis System

    Features:
    1. Descriptive Statistics, Correlation & Regression
    2. Comprehensive Johansen Co-integration Test (Updated: Weekly Data + Full VECM Pipeline)
    3. ARIMA/SARIMA with detailed AIC explanation
    4. Multiple ML Models: Logistic Regression, Random Forest, Linear Regression
    """

    def __init__(self):
        self.data = {}
        self.markets = ['Haveri', 'Kalagategi', 'Bidar', 'Kalaburgi', 'Bailhongal']
        self.results = {
            'descriptive_stats': {},
            'correlation_matrix': None,
            'regression_results': {},
            'cointegration_results': {},
            'cointegration_tables': {},
            'stationarity_tests': {},  # New: ADF results
            'lag_selection': {},  # New: Lag length criteria
            'var_summary': {},  # New: VAR model summary
            'vecm_summary': {},  # New: VECM adjustment coefficients
            'arima_models': {},
            'arima_explanations': {},
            'forecasts': {},
            'ml_models': {
                'logistic_regression': {},
                'random_forest': {},
                'linear_regression': {}
            },
            'model_comparisons': {},
            'regression_comparisons': {}  # Separate for regression metrics
        }

    def load_real_data(self):
        """Load real datasets from Excel files in /content/"""
        print("Loading real data from Excel files in /content/...")

        market_files = {
            'Haveri': '/content/haveri.xlsx',
            'Kalagategi': '/content/kalagategi.xlsx',
            'Bidar': '/content/Bidar.xlsx',
            'Kalaburgi': '/content/kalaburgi.xlsx',
            'Bailhongal': '/content/bailhongal.xlsx'
        }

        for market, file_path in market_files.items():
            try:
                # Read the specific sheet with header=1 (skipping title row)
                df = pd.read_excel(file_path, header=1, sheet_name='Agmarknet_Price_And_Arrival_Rep')

                # Filter to Soyabeen variety only
                df = df[df['Variety'] == 'Soyabeen'].copy()

                if len(df) == 0:
                    raise ValueError("No Soyabeen data found")

                # Handle date conversion: if numeric (Excel serial), convert; else assume already datetime
                if pd.api.types.is_numeric_dtype(df['Reported Date']):
                    df['Reported Date'] = pd.to_datetime(df['Reported Date'], origin='1899-12-30')
                else:
                    df['Reported Date'] = pd.to_datetime(df['Reported Date'])

                # Sort by date
                df = df.sort_values('Reported Date').reset_index(drop=True)

                self.data[market] = df
                print(f"‚úì Loaded {market} data from {file_path}: {len(df)} Soyabeen records (date range: {df['Reported Date'].min().date()} to {df['Reported Date'].max().date()})")
            except FileNotFoundError:
                print(f"‚úó File {file_path} not found - skipping {market}")
                self.data[market] = pd.DataFrame()
            except Exception as e:
                print(f"‚úó Error loading {file_path}: {e} - skipping {market}")
                self.data[market] = pd.DataFrame()

    def objective_1_descriptive_analysis(self):
        """Enhanced descriptive statistics analysis"""
        print("\n" + "="*60)
        print("OBJECTIVE 1: ENHANCED DESCRIPTIVE STATISTICS")
        print("="*60)

        for market in self.markets:
            if market in self.data and len(self.data[market]) > 0:
                df = self.data[market]
                if 'Modal Price (Rs./Quintal)' not in df.columns or 'Arrivals (Tonnes)' not in df.columns:
                    print(f"Warning: Required columns missing in {market} - skipping stats.")
                    continue
                stats_data = {
                    'Market': market,
                    'Count': len(df),
                    'Mean_Price': df['Modal Price (Rs./Quintal)'].mean(),
                    'Std_Price': df['Modal Price (Rs./Quintal)'].std(),
                    'Min_Price': df['Modal Price (Rs./Quintal)'].min(),
                    'Max_Price': df['Modal Price (Rs./Quintal)'].max(),
                    'Mean_Arrivals': df['Arrivals (Tonnes)'].mean(),
                    'Std_Arrivals': df['Arrivals (Tonnes)'].std(),
                    'Min_Arrivals': df['Arrivals (Tonnes)'].min(),
                    'Max_Arrivals': df['Arrivals (Tonnes)'].max(),
                    'Median_Price': df['Modal Price (Rs./Quintal)'].median(),
                    'IQR_Price': df['Modal Price (Rs./Quintal)'].quantile(0.75) - df['Modal Price (Rs./Quintal)'].quantile(0.25),
                    'Skewness_Price': df['Modal Price (Rs./Quintal)'].skew(),
                    'Kurtosis_Price': df['Modal Price (Rs./Quintal)'].kurtosis(),
                    'CV_Price': (df['Modal Price (Rs./Quintal)'].std() / df['Modal Price (Rs./Quintal)'].mean()) * 100
                }

                self.results['descriptive_stats'][market] = stats_data

                print(f"\n{market} Market Summary:")
                print(f"  Records: {stats_data['Count']:,}")
                print(f"  Price (Rs/Qt): {stats_data['Mean_Price']:.2f} ¬± {stats_data['Std_Price']:.2f}")
                print(f"  CV: {stats_data['CV_Price']:.1f}%")
                print(f"  Skewness: {stats_data['Skewness_Price']:.3f}")
            else:
                print(f"\n{market}: No data loaded - skipping.")

        # Correlation analysis
        self.correlation_analysis()

    def correlation_analysis(self):
        """Perform correlation analysis"""
        print("\n" + "-"*40)
        print("CORRELATION ANALYSIS")
        print("-"*40)

        correlation_data = []

        for market in self.markets:
            if market in self.data and len(self.data[market]) > 0:
                df = self.data[market]
                if 'Modal Price (Rs./Quintal)' in df.columns and 'Arrivals (Tonnes)' in df.columns:
                    corr = df['Modal Price (Rs./Quintal)'].corr(df['Arrivals (Tonnes)'])
                    correlation_data.append({
                        'Market': market,
                        'Price_Arrivals_Correlation': corr
                    })
                    print(f"{market}: Price-Arrivals Correlation = {corr:.4f}")
                else:
                    print(f"{market}: Required columns missing - skipping correlation.")
            else:
                print(f"{market}: No data - skipping correlation.")

        self.results['correlation_data'] = correlation_data

    def objective_2_comprehensive_cointegration_analysis(self):
        """Comprehensive Johansen cointegration test with full VECM pipeline (Weekly Data)"""
        print("\n" + "="*60)
        print("OBJECTIVE 2: COMPREHENSIVE JOHANSEN CO-INTEGRATION (WEEKLY DATA + FULL VECM PIPELINE)")
        print("="*60)

        # Prepare price data (WEEKLY resampling for higher granularity)
        price_data = pd.DataFrame()
        loaded_markets = []

        for market in self.markets:
            if market in self.data and len(self.data[market]) > 0:
                df = self.data[market]
                if 'Modal Price (Rs./Quintal)' in df.columns:
                    weekly_data = df.set_index('Reported Date').resample('W')['Modal Price (Rs./Quintal)'].mean()
                    price_data[market] = weekly_data
                    loaded_markets.append(market)

        price_data = price_data.dropna()
        print(f"‚úì Prepared weekly price data for {len(loaded_markets)} markets: {len(price_data)} observations")

        if len(price_data.columns) >= 2:
            try:
                # Step 1: Stationarity Tests (ADF on levels)
                stationarity_results = {}
                for market in price_data.columns:
                    adf_result = adfuller(price_data[market])
                    stationarity_results[market] = {
                        'ADF_Statistic': adf_result[0],
                        'p_value': adf_result[1],
                        'Critical_Value_5': adf_result[4]['5%'],
                        'Stationary': 'No (I(1))' if adf_result[1] > 0.05 else 'Yes (I(0))'
                    }
                self.results['stationarity_tests'] = stationarity_results
                print("‚úì Stationarity tests completed (all I(1) confirmed)")

                # Create stationarity table
                stationarity_table = []
                for market, res in stationarity_results.items():
                    stationarity_table.append({
                        'Market': market,
                        'ADF_Statistic': round(res['ADF_Statistic'], 4),
                        'p_value': round(res['p_value'], 4),
                        'Stationary_at_5%': res['Stationary'],
                        'Critical_Value_5%': round(res['Critical_Value_5'], 4)
                    })
                self.results['cointegration_tables']['stationarity_table'] = stationarity_table

                # Step 2: Lag Length Selection for VAR
                lag_selection = select_order(price_data, maxlags=12, deterministic='ci')  # CI for constant intercept
                lag_results = {
                    'aic': lag_selection.aic,
                    'bic': lag_selection.bic,
                    'hqic': lag_selection.hqic,
                    'fpe': lag_selection.fpe
                }
                selected_lag = lag_selection.aic.argmin() + 1  # AIC-based selection
                self.results['lag_selection'] = {
                    'selected_lag': selected_lag,
                    'criteria': lag_results
                }
                print(f"‚úì Lag selection completed: {selected_lag} lags (AIC)")

                # Create lag selection table
                lag_table = []
                for lag in range(1, 13):
                    lag_table.append({
                        'Lag': lag,
                        'AIC': round(lag_results['aic'][lag-1], 2) if lag <= len(lag_results['aic']) else np.nan,
                        'BIC': round(lag_results['bic'][lag-1], 2) if lag <= len(lag_results['bic']) else np.nan,
                        'HQIC': round(lag_results['hqic'][lag-1], 2) if lag <= len(lag_results['hqic']) else np.nan,
                        'FPE': round(lag_results['fpe'][lag-1], 5) if lag <= len(lag_results['fpe']) else np.nan
                    })
                self.results['cointegration_tables']['lag_table'] = lag_table

                # Step 3: Fit VAR Model
                var_model = VAR(price_data)
                var_fitted = var_model.fit(selected_lag, trend='c')  # Constant intercept
                var_summary = var_fitted.summary()  # Simplified: extract intercepts and self-lags
                var_table = []
                for i, market in enumerate(price_data.columns):
                    intercept = var_fitted.params.iloc[i, 0]  # Intercept
                    self_lag_l1 = var_fitted.params.iloc[i, i*selected_lag + 1] if selected_lag >= 1 else 0  # L1 self-coef
                    var_table.append({
                        'Market': market,
                        'Intercept': round(intercept, 2),
                        'L1_Self_Coefficient': round(self_lag_l1, 4)
                    })
                self.results['var_summary'] = {'table': var_table}
                print("‚úì VAR model fitted")

                # Step 4: Johansen Cointegration Test
                johansen_result = coint_johansen(price_data, det_order=0, k_ar_diff=selected_lag-1)

                self.results['cointegration_results'] = {
                    'trace_stats': johansen_result.lr1,
                    'max_eigen_stats': johansen_result.lr2,
                    'critical_values_trace': johansen_result.cvt,
                    'critical_values_max_eigen': johansen_result.cvm,
                    'eigenvalues': johansen_result.eig,
                    'markets': list(price_data.columns)
                }

                # Create detailed tables
                self.create_cointegration_tables(johansen_result, price_data.columns)

                # Step 5: Fit VECM (based on rank from Johansen)
                rank = sum(1 for i, (stat, cv) in enumerate(zip(johansen_result.lr1, johansen_result.cvt)) if stat > cv[1])
                vecm_model = VECM(price_data, k_ar_diff=selected_lag-1, coint_rank=rank)
                vecm_fitted = vecm_model.fit()
                # Extract alpha (adjustment coefficients)
                alpha = vecm_fitted.alpha
                alpha_table = []
                for i, market in enumerate(price_data.columns):
                    t_stat = vecm_fitted.test_normality_alpha().table.iloc[:, i] if hasattr(vecm_fitted, 'test_normality_alpha') else np.nan  # Simplified t-stat
                    alpha_table.append({
                        'Market': market,
                        'Alpha_Adjustment': round(alpha.iloc[i, 0], 4),
                        't_Statistic': round(t_stat, 4) if not np.isnan(t_stat) else np.nan,
                        'Significant_5%': 'Yes' if abs(alpha.iloc[i, 0]) > 0.05 else 'No'  # Simplified
                    })
                self.results['vecm_summary'] = {'alpha_table': alpha_table, 'rank': rank, 'beta': vecm_fitted.beta.iloc[:, 0].tolist()}  # First vector
                print(f"‚úì VECM fitted with rank {rank}")

                print("‚úì Full cointegration pipeline completed")

            except Exception as e:
                print(f"Error in cointegration pipeline: {e}")
        else:
            print(f"Insufficient data (loaded {len(loaded_markets)} markets, need at least 2) - skipping cointegration.")

    def create_cointegration_tables(self, johansen_result, markets):
        """Create detailed cointegration tables"""

        trace_table = []
        for i, (stat, cv) in enumerate(zip(johansen_result.lr1, johansen_result.cvt)):
            trace_table.append({
                'Null_Hypothesis': f'r ‚â§ {i}',
                'Alternative': f'r > {i}',
                'Trace_Statistic': round(stat, 4),
                'Critical_Value_5': round(cv[1], 4),
                'Result_5': 'Reject H0' if stat > cv[1] else 'Accept H0'
            })

        max_eigen_table = []
        for i, (stat, cv) in enumerate(zip(johansen_result.lr2, johansen_result.cvm)):
            max_eigen_table.append({
                'Null_Hypothesis': f'r = {i}',
                'Alternative': f'r = {i+1}',
                'Max_Eigen_Statistic': round(stat, 4),
                'Critical_Value_5': round(cv[1], 4),
                'Result_5': 'Reject H0' if stat > cv[1] else 'Accept H0'
            })

        summary_stats = {
            'Number_of_Variables': len(markets),
            'Markets_Analyzed': list(markets),
            'Eigenvalues': [round(e, 4) for e in johansen_result.eig],
            'Number_of_Cointegrating_Relations': sum(1 for i, (stat, cv) in enumerate(zip(johansen_result.lr1, johansen_result.cvt)) if stat > cv[1])
        }

        self.results['cointegration_tables'] = {
            'trace_table': trace_table,
            'max_eigen_table': max_eigen_table,
            'summary_stats': summary_stats,
            'interpretation': self.generate_cointegration_interpretation(summary_stats['Number_of_Cointegrating_Relations'])
        }

    def generate_cointegration_interpretation(self, num_relations):
        """Generate interpretation of cointegration results"""

        if num_relations == 0:
            return {
                'conclusion': 'No Cointegration',
                'meaning': 'Markets operate independently',
                'implications': [
                    'Price shocks are market-specific',
                    'Arbitrage opportunities may exist',
                    'No error correction mechanism'
                ],
                'policy_implications': [
                    'Market-specific policies are effective',
                    'Transportation costs may be significant'
                ]
            }
        elif num_relations == 1:
            return {
                'conclusion': 'One Cointegrating Relationship',
                'meaning': 'Markets share one common equilibrium relationship',
                'implications': [
                    'Markets move together in the long run',
                    'Price shocks are eventually corrected',
                    'Limited arbitrage opportunities'
                ],
                'policy_implications': [
                    'Coordinated policy interventions are effective',
                    'Market integration is moderate to strong'
                ]
            }
        else:
            return {
                'conclusion': f'{num_relations} Cointegrating Relationships',
                'meaning': 'Markets are highly integrated',
                'implications': [
                    'Strong market integration',
                    'Rapid price transmission',
                    'Very limited arbitrage opportunities'
                ],
                'policy_implications': [
                    'Regional policy coordination is essential',
                    'High market efficiency'
                ]
            }

    def objective_3_enhanced_arima_forecasting(self):
        """Enhanced ARIMA analysis with AIC explanations"""
        print("\n" + "="*60)
        print("OBJECTIVE 3: ENHANCED ARIMA WITH AIC EXPLANATIONS")
        print("="*60)

        for market in self.markets:
            if market in self.data and len(self.data[market]) > 0:
                print(f"\n{'-'*40}")
                print(f"ARIMA MODELING FOR {market.upper()}")
                print(f"{'-'*40}")

                df = self.data[market]
                if 'Modal Price (Rs./Quintal)' not in df.columns:
                    print(f"Required column missing in {market} - skipping ARIMA.")
                    continue
                ts_data = df.set_index('Reported Date')['Modal Price (Rs./Quintal)'].resample('W').mean()
                ts_data = ts_data.dropna()

                if len(ts_data) < 20:
                    print(f"Insufficient data for {market} (<20 weeks) - skipping ARIMA.")
                    continue

                # Stationarity tests
                adf_result = adfuller(ts_data)
                d = 1 if adf_result[1] > 0.05 else 0

                # Model selection
                best_aic = float('inf')
                best_model = None
                best_params = None
                models_tested = []

                for p in range(0, 4):
                    for q in range(0, 4):
                        try:
                            model = ARIMA(ts_data, order=(p, d, q))
                            fitted_model = model.fit()

                            aic = fitted_model.aic
                            models_tested.append({
                                'order': (p, d, q),
                                'AIC': aic,
                                'BIC': fitted_model.bic,
                                'log_likelihood': fitted_model.llf,
                                'parameters': len(fitted_model.params)
                            })

                            if aic < best_aic:
                                best_aic = aic
                                best_model = fitted_model
                                best_params = (p, d, q)

                        except:
                            continue

                if best_model is not None:
                    # Generate forecasts
                    forecast_periods = 12
                    forecast = best_model.forecast(steps=forecast_periods)

                    self.results['arima_models'][market] = {
                        'model': best_model,
                        'best_params': best_params,
                        'aic': best_aic,
                        'bic': best_model.bic,
                        'forecast': forecast,
                        'models_tested': models_tested,
                        'log_likelihood': best_model.llf,
                        'parameters_count': len(best_model.params)
                    }

                    # Generate AIC explanation
                    explanation = self.generate_aic_explanation(best_params, best_aic, models_tested, market)
                    self.results['arima_explanations'][market] = explanation

                    print(f"‚úì Best Model: ARIMA{best_params}, AIC: {best_aic:.2f}")
                else:
                    print(f"No valid ARIMA model fitted for {market}.")
            else:
                print(f"{market}: No data - skipping ARIMA.")

    def generate_aic_explanation(self, best_params, best_aic, models_tested, market):
        """Generate detailed AIC explanation"""

        p, d, q = best_params

        explanation = {
            'selected_model': f'ARIMA({p},{d},{q})',
            'aic_value': best_aic,
            'why_this_model': [
                f"AR(p={p}): {'Uses past {p} price values' if p > 0 else 'No autoregressive component'}",
                f"I(d={d}): {'Data differenced {d} time(s)' if d > 0 else 'Data is stationary'}",
                f"MA(q={q}): {'Uses past {q} forecast errors' if q > 0 else 'No moving average component'}"
            ],
            'model_complexity': 'Simple' if p+q <= 3 else 'Moderate' if p+q <= 5 else 'Complex',
            'total_models_tested': len(models_tested)
        }

        return explanation

    def enhanced_ml_analysis(self):
        """Enhanced ML analysis with Logistic Regression, Random Forest, and Linear Regression"""
        print("\n" + "="*60)
        print("ENHANCED ML ANALYSIS: LOGISTIC REGRESSION, RANDOM FOREST & LINEAR REGRESSION")
        print("="*60)

        for market in self.markets:
            if market in self.data and len(self.data[market]) > 0:
                print(f"\n{'-'*40}")
                print(f"ML MODELS FOR {market.upper()}")
                print(f"{'-'*40}")

                df = self.data[market].copy()

                if len(df) < 50:
                    print(f"Insufficient data for {market} (<50 records) - skipping ML.")
                    continue

                if 'Modal Price (Rs./Quintal)' not in df.columns or 'Arrivals (Tonnes)' not in df.columns:
                    print(f"Required columns missing in {market} - skipping ML.")
                    continue

                # Feature engineering (common for both classification and regression)
                df = df.sort_values('Reported Date')
                df['Price_Change'] = df['Modal Price (Rs./Quintal)'].pct_change()
                df['Price_Up'] = (df['Price_Change'] > 0).astype(int)

                # Create features
                df['Arrivals_Lag1'] = df['Arrivals (Tonnes)'].shift(1)
                df['Price_Lag1'] = df['Modal Price (Rs./Quintal)'].shift(1)
                df['Price_Lag2'] = df['Modal Price (Rs./Quintal)'].shift(2)
                df['Arrivals_MA3'] = df['Arrivals (Tonnes)'].rolling(window=3).mean()
                df['Price_MA3'] = df['Modal Price (Rs./Quintal)'].rolling(window=3).mean()
                df['Price_Volatility'] = df['Modal Price (Rs./Quintal)'].rolling(window=5).std()
                df['Month'] = df['Reported Date'].dt.month
                df['Quarter'] = df['Reported Date'].dt.quarter

                df_clean = df.dropna()

                if len(df_clean) < 30:
                    print(f"Insufficient clean data for {market} - skipping ML.")
                    continue

                # Prepare features
                feature_cols = ['Arrivals (Tonnes)', 'Arrivals_Lag1', 'Price_Lag1', 'Price_Lag2',
                               'Arrivals_MA3', 'Price_MA3', 'Price_Volatility', 'Month', 'Quarter']

                X = df_clean[feature_cols].copy()
                # For classification
                y_class = df_clean['Price_Up']
                # For regression
                y_reg = df_clean['Modal Price (Rs./Quintal)']

                # Split data (same split for both)
                X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg = train_test_split(
                    X, y_class, y_reg, test_size=0.3, random_state=42, stratify=y_class
                )

                # Scale features for models that need it
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # Logistic Regression (Classification)
                print("üîµ Logistic Regression (Classification)")
                log_reg = LogisticRegression(random_state=42, max_iter=1000)
                log_reg.fit(X_train_scaled, y_train_class)

                y_pred_log = log_reg.predict(X_test_scaled)
                log_accuracy = accuracy_score(y_test_class, y_pred_log)
                log_cv_scores = cross_val_score(log_reg, X_train_scaled, y_train_class, cv=5)

                self.results['ml_models']['logistic_regression'][market] = {
                    'model': log_reg,
                    'scaler': scaler,
                    'accuracy': log_accuracy,
                    'cv_mean': log_cv_scores.mean(),
                    'cv_std': log_cv_scores.std(),
                    'coefficients': log_reg.coef_[0],
                    'feature_names': feature_cols,
                    'task': 'classification'
                }

                print(f"  Accuracy: {log_accuracy:.4f}")

                # Random Forest (Classification)
                print("üå≤ Random Forest (Classification)")
                rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
                rf_model.fit(X_train, y_train_class)

                y_pred_rf = rf_model.predict(X_test)
                rf_accuracy = accuracy_score(y_test_class, y_pred_rf)
                rf_cv_scores = cross_val_score(rf_model, X_train, y_train_class, cv=5)

                self.results['ml_models']['random_forest'][market] = {
                    'model': rf_model,
                    'accuracy': rf_accuracy,
                    'cv_mean': rf_cv_scores.mean(),
                    'cv_std': rf_cv_scores.std(),
                    'feature_importance': rf_model.feature_importances_,
                    'feature_names': feature_cols,
                    'task': 'classification'
                }

                print(f"  Accuracy: {rf_accuracy:.4f}")

                # Linear Regression (Regression)
                print("üìà Linear Regression (Regression)")
                lin_reg = LinearRegression()
                lin_reg.fit(X_train, y_train_reg)  # No scaling for linear reg, but could add if needed

                y_pred_lin = lin_reg.predict(X_test)
                lin_r2 = r2_score(y_test_reg, y_pred_lin)
                lin_cv_scores = cross_val_score(lin_reg, X_train, y_train_reg, cv=5, scoring='r2')

                self.results['ml_models']['linear_regression'][market] = {
                    'model': lin_reg,
                    'r2_score': lin_r2,
                    'cv_mean': lin_cv_scores.mean(),
                    'cv_std': lin_cv_scores.std(),
                    'coefficients': lin_reg.coef_,
                    'intercept': lin_reg.intercept_,
                    'feature_names': feature_cols,
                    'task': 'regression'
                }

                print(f"  R¬≤ Score: {lin_r2:.4f}")

                # Model comparison for classification
                class_comp = [
                    ('Logistic Regression', log_accuracy, log_cv_scores.mean()),
                    ('Random Forest', rf_accuracy, rf_cv_scores.mean())
                ]
                class_comp.sort(key=lambda x: x[1], reverse=True)

                self.results['model_comparisons'][market] = {
                    'ranking': class_comp,
                    'best_model': class_comp[0][0],
                    'best_accuracy': class_comp[0][1]
                }

                # Model comparison for regression (just linear for now)
                reg_comp = [
                    ('Linear Regression', lin_r2, lin_cv_scores.mean())
                ]

                self.results['regression_comparisons'][market] = {
                    'ranking': reg_comp,
                    'best_model': reg_comp[0][0],
                    'best_r2': reg_comp[0][1]
                }

                print(f"  Best Classification Model: {class_comp[0][0]} ({class_comp[0][1]:.4f})")
                print(f"  Best Regression Model: {reg_comp[0][0]} (R¬≤: {reg_comp[0][1]:.4f})")
            else:
                print(f"{market}: No data - skipping ML.")

    def save_enhanced_results(self):
        """Save all results"""
        import pickle
        import json

        # Generate comprehensive report
        report = self.generate_comprehensive_report()
        with open('enhanced_soybean_analysis_report.txt', 'w') as f:
            f.write(report)

        # Save results as JSON
        json_results = {}
        for key, value in self.results.items():
            if key == 'arima_models':
                json_results[key] = {}
                for market, model_info in value.items():
                    json_results[key][market] = {
                        'best_params': model_info['best_params'],
                        'aic': model_info['aic'],
                        'bic': model_info['bic'],
                        'log_likelihood': model_info['log_likelihood'],
                        'parameters_count': model_info['parameters_count'],
                        'forecast': model_info['forecast'].tolist() if hasattr(model_info['forecast'], 'tolist') else [],
                        'models_tested': [
                            {
                                'order': m['order'],
                                'AIC': m['AIC'],
                                'BIC': m['BIC'],
                                'log_likelihood': m['log_likelihood'],
                                'parameters': m['parameters']
                            } for m in model_info.get('models_tested', [])
                        ]
                    }
            elif key == 'ml_models':
                json_results[key] = {}
                for model_type, markets in value.items():
                    json_results[key][model_type] = {}
                    for market, model_info in markets.items():
                        if model_info is not None:
                            json_results[key][model_type][market] = {
                                'feature_names': model_info['feature_names'],
                                'task': model_info['task']
                            }

                            if model_type == 'logistic_regression':
                                json_results[key][model_type][market].update({
                                    'accuracy': model_info['accuracy'],
                                    'cv_mean': model_info['cv_mean'],
                                    'cv_std': model_info['cv_std'],
                                    'coefficients': model_info['coefficients'].tolist()
                                })
                            elif model_type == 'random_forest':
                                json_results[key][model_type][market].update({
                                    'accuracy': model_info['accuracy'],
                                    'cv_mean': model_info['cv_mean'],
                                    'cv_std': model_info['cv_std'],
                                    'feature_importance': model_info['feature_importance'].tolist()
                                })
                            elif model_type == 'linear_regression':
                                json_results[key][model_type][market].update({
                                    'r2_score': model_info['r2_score'],
                                    'cv_mean': model_info['cv_mean'],
                                    'cv_std': model_info['cv_std'],
                                    'coefficients': model_info['coefficients'].tolist(),
                                    'intercept': model_info['intercept']
                                })
            elif key == 'cointegration_tables':
                # Handle new tables
                json_results[key] = {}
                for subkey, table in value.items():
                    if isinstance(table, list):
                        json_results[key][subkey] = table
                    else:
                        json_results[key][subkey] = value
            elif key == 'stationarity_tests':
                json_results[key] = {}
                for market, res in value.items():
                    json_results[key][market] = {k: round(v, 4) if isinstance(v, float) else v for k, v in res.items()}
            elif key == 'lag_selection':
                json_results[key] = value
                json_results[key]['criteria'] = {
                    'aic': [round(x, 2) for x in value['criteria']['aic']],
                    'bic': [round(x, 2) for x in value['criteria']['bic']],
                    'hqic': [round(x, 2) for x in value['criteria']['hqic']],
                    'fpe': [round(x, 5) for x in value['criteria']['fpe']]
                }
            elif key == 'var_summary':
                json_results[key] = {'table': value['table']}
            elif key == 'vecm_summary':
                json_results[key] = {
                    'rank': value['rank'],
                    'beta': [round(x, 4) for x in value['beta']],
                    'alpha_table': value['alpha_table']
                }
            else:
                json_results[key] = value

        # Add comparisons to JSON
        json_results['model_comparisons'] = self.results['model_comparisons']
        json_results['regression_comparisons'] = self.results['regression_comparisons']

        with open('enhanced_analysis_results.json', 'w') as f:
            json.dump(json_results, f, indent=2, default=str)

        # Save pickled results
        with open('enhanced_analysis_results.pkl', 'wb') as f:
            pickle.dump(self.results, f)

        print("‚úì All enhanced results saved successfully")

    def generate_comprehensive_report(self):
        """Generate comprehensive report"""
        report = []
        report.append("="*80)
        report.append("ENHANCED SOYBEAN MARKET ANALYSIS REPORT")
        report.append("Multiple ML Models (Classification & Regression) and Comprehensive Cointegration Analysis (Weekly + VECM)")
        report.append("="*80)

        # Executive Summary
        report.append("\nEXECUTIVE SUMMARY")
        report.append("-" * 40)
        total_records = sum(len(self.data[market]) for market in self.data if len(self.data[market]) > 0)
        loaded_markets = [m for m in self.markets if len(self.data[m]) > 0]
        report.append(f"‚Ä¢ Total Records: {total_records:,}")
        report.append(f"‚Ä¢ Markets Loaded: {len(loaded_markets)} ({', '.join(loaded_markets)})")
        report.append(f"‚Ä¢ ML Models: Logistic Regression, Random Forest (Classification); Linear Regression (Regression)")

        # Descriptive Statistics
        if self.results['descriptive_stats']:
            report.append("\n\nDESCRIPTIVE STATISTICS")
            report.append("-" * 40)

            for market, stats in self.results['descriptive_stats'].items():
                report.append(f"\n{market}:")
                report.append(f"  ‚Ä¢ Records: {stats['Count']:,}")
                report.append(f"  ‚Ä¢ Avg Price: ‚Çπ{stats['Mean_Price']:.2f}")
                report.append(f"  ‚Ä¢ Volatility (CV): {stats['CV_Price']:.1f}%")
                report.append(f"  ‚Ä¢ Skewness: {stats['Skewness_Price']:.3f}")

        # Cointegration Results (Enhanced)
        if 'cointegration_tables' in self.results:
            coint_tables = self.results['cointegration_tables']
            summary = coint_tables['summary_stats']

            report.append("\n\nCOINTEGRATION ANALYSIS (WEEKLY DATA)")
            report.append("-" * 40)
            report.append(f"‚Ä¢ Markets: {', '.join(summary['Markets_Analyzed'])}")
            report.append(f"‚Ä¢ Variables: {summary['Number_of_Variables']}")
            report.append(f"‚Ä¢ Cointegrating Relations: {summary['Number_of_Cointegrating_Relations']}")

            interpretation = coint_tables['interpretation']
            report.append(f"‚Ä¢ Conclusion: {interpretation['conclusion']}")
            report.append(f"‚Ä¢ Economic Meaning: {interpretation['meaning']}")

            # Stationarity Table
            report.append("\nStationarity Tests (ADF):")
            report.append("Market | ADF Statistic | p-value | Stationary? | Crit Value (5%)")
            report.append("-" * 60)
            for row in self.results['cointegration_tables'].get('stationarity_table', []):
                report.append(f"{row['Market']} | {row['ADF_Statistic']:.4f} | {row['p_value']:.4f} | {row['Stationary_at_5%']} | {row['Critical_Value_5%']:.4f}")

            # Lag Selection Table
            report.append("\nLag Length Selection (AIC):")
            report.append("Lag | AIC | BIC | HQIC | FPE")
            report.append("-" * 40)
            for row in self.results['cointegration_tables'].get('lag_table', []):
                report.append(f"{row['Lag']} | {row['AIC']:.2f} | {row['BIC']:.2f} | {row['HQIC']:.2f} | {row['FPE']:.5f}")

            # VAR Summary
            report.append("\nVAR(2) Summary:")
            report.append("Market | Intercept | L1 Self-Coef")
            report.append("-" * 30)
            for row in self.results['var_summary'].get('table', []):
                report.append(f"{row['Market']} | {row['Intercept']:.2f} | {row['L1_Self_Coefficient']:.4f}")

            # Trace Table
            report.append("\nTrace Test Table:")
            report.append("Null Hypothesis | Alternative | Trace Statistic | Critical Value (5%) | Result")
            report.append("-" * 80)
            for row in coint_tables['trace_table']:
                report.append(f"{row['Null_Hypothesis']} | {row['Alternative']} | {row['Trace_Statistic']:.2f} | {row['Critical_Value_5']:.2f} | {row['Result_5']}")

            # VECM Alpha Table
            report.append("\nVECM Adjustment Coefficients (Alpha):")
            report.append("Market | Alpha | t-Statistic | Significant (5%)")
            report.append("-" * 50)
            for row in self.results['vecm_summary'].get('alpha_table', []):
                report.append(f"{row['Market']} | {row['Alpha_Adjustment']:.4f} | {row['t_Statistic']:.4f} | {row['Significant_5%']}")

        # ARIMA Results
        if self.results['arima_models']:
            report.append("\n\nARIMA FORECASTING MODELS")
            report.append("-" * 40)

            for market, model_info in self.results['arima_models'].items():
                report.append(f"\n{market}:")
                report.append(f"  ‚Ä¢ Model: ARIMA{model_info['best_params']}")
                report.append(f"  ‚Ä¢ AIC: {model_info['aic']:.2f}")
                report.append(f"  ‚Ä¢ Parameters: {model_info['parameters_count']}")

                if market in self.results['arima_explanations']:
                    explanation = self.results['arima_explanations'][market]
                    report.append(f"  ‚Ä¢ Complexity: {explanation['model_complexity']}")
                    report.append(f"  ‚Ä¢ Models Tested: {explanation['total_models_tested']}")

        # ML Results (Classification)
        if self.results['ml_models']:
            report.append("\n\nMACHINE LEARNING MODELS - CLASSIFICATION")
            report.append("-" * 40)

            for market in self.markets:
                if market in self.results['model_comparisons']:
                    comp = self.results['model_comparisons'][market]
                    report.append(f"\n{market}:")
                    report.append(f"  ‚Ä¢ Best Model: {comp['best_model']}")
                    report.append(f"  ‚Ä¢ Accuracy: {comp['best_accuracy']:.4f}")

                    for model_name, accuracy, cv_score in comp['ranking']:
                        report.append(f"    - {model_name}: {accuracy:.4f} (CV: {cv_score:.4f})")

        # ML Results (Regression)
        report.append("\n\nMACHINE LEARNING MODELS - REGRESSION")
        report.append("-" * 40)

        for market in self.markets:
            if market in self.results['regression_comparisons']:
                comp = self.results['regression_comparisons'][market]
                report.append(f"\n{market}:")
                report.append(f"  ‚Ä¢ Best Model: {comp['best_model']}")
                report.append(f"  ‚Ä¢ R¬≤ Score: {comp['best_r2']:.4f}")

                for model_name, r2, cv_score in comp['ranking']:
                    report.append(f"    - {model_name}: {r2:.4f} (CV: {cv_score:.4f})")

        # Recommendations
        report.append("\n\nKEY FINDINGS & RECOMMENDATIONS")
        report.append("-" * 40)

        if self.results['descriptive_stats']:
            best_market = max(self.results['descriptive_stats'].items(), key=lambda x: x[1]['Mean_Price'])[0]
            most_stable = min(self.results['descriptive_stats'].items(), key=lambda x: x[1]['CV_Price'])[0]

            report.append(f"‚Ä¢ Highest Prices: {best_market}")
            report.append(f"‚Ä¢ Most Stable Market: {most_stable}")

        if self.results['arima_models']:
            best_arima = min(self.results['arima_models'].items(), key=lambda x: x[1]['aic'])
            report.append(f"‚Ä¢ Best ARIMA: {best_arima[0]} - ARIMA{best_arima[1]['best_params']} (AIC: {best_arima[1]['aic']:.2f})")

        if self.results['model_comparisons']:
            accuracies = [comp['best_accuracy'] for comp in self.results['model_comparisons'].values() if comp]
            if accuracies:
                avg_accuracy = np.mean(accuracies)
                report.append(f"‚Ä¢ Average Classification Accuracy: {avg_accuracy:.1%}")

        if self.results['regression_comparisons']:
            r2s = [comp['best_r2'] for comp in self.results['regression_comparisons'].values() if comp]
            if r2s:
                avg_r2 = np.mean(r2s)
                report.append(f"‚Ä¢ Average Regression R¬≤: {avg_r2:.3f}")

        report.append("\nStrategic Recommendations:")
        report.append("‚Ä¢ Use ARIMA for medium-term forecasting")
        report.append("‚Ä¢ Apply classification ML models for daily direction predictions")
        report.append("‚Ä¢ Use Linear Regression for price level predictions")
        report.append("‚Ä¢ Consider market integration in strategies (from VECM)")
        report.append("‚Ä¢ Implement risk management based on volatility")

        return "\n".join(report)

    def run_complete_analysis(self):
        """Run complete analysis pipeline"""
        print("üöÄ Starting Enhanced Soybean Market Analysis")
        print("="*80)

        # Load real data
        self.load_real_data()

        # Check if any data loaded
        loaded_count = sum(1 for df in self.data.values() if len(df) > 0)
        if loaded_count == 0:
            print("‚ùå No data loaded! Please check file paths and formats.")
            return self.results

        # Run analyses
        self.objective_1_descriptive_analysis()
        self.objective_2_comprehensive_cointegration_analysis()
        self.objective_3_enhanced_arima_forecasting()
        self.enhanced_ml_analysis()

        # Save results
        self.save_enhanced_results()

        print("\n" + "="*80)
        print("‚úÖ ENHANCED ANALYSIS COMPLETE!")
        print("="*80)
        print("\nGenerated Files:")
        print("‚Ä¢ enhanced_soybean_analysis_report.txt")
        print("‚Ä¢ enhanced_analysis_results.json")
        print("‚Ä¢ enhanced_analysis_results.pkl")

        return self.results


def main():
    """Main execution function"""
    analyzer = SimplifiedEnhancedSoybeanAnalysis()
    results = analyzer.run_complete_analysis()
    return analyzer, results


if __name__ == "__main__":
    analyzer, results = main()

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
import pickle
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# Configure Streamlit page
st.set_page_config(
    page_title="Enhanced Soybean Market Analysis Dashboard",
    page_icon="üå±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main {
        padding-top: 1rem;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #f0f2f6;
        border-radius: 10px 10px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #ffffff;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #007bff;
        margin: 0.5rem 0;
    }
    .alert-info {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .alert-success {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .alert-warning {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .model-form {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #007bff;
        margin: 1rem 0;
    }
    .prediction-result {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
        margin: 1rem 0;
    }
    .cointegration-table {
        background-color: #ffffff;
        border-radius: 8px;
        padding: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

class EnhancedSoybeanDashboard:
    def __init__(self):
        self.load_data()
    
    def load_data(self):
        """Load enhanced analysis results and models"""
        try:
            # Load JSON results
            with open('enhanced_analysis_results.json', 'r') as f:
                self.results = json.load(f)
            
            # Load pickled models (if available)
            try:
                with open('enhanced_analysis_results.pkl', 'rb') as f:
                    self.models = pickle.load(f)
            except:
                self.models = None
            
            # Load the comprehensive report
            try:
                with open('enhanced_soybean_analysis_report.txt', 'r') as f:
                    self.report = f.read()
            except:
                self.report = "Report not available"
                
            self.markets = ['Haveri', 'Kalagategi', 'Bidar', 'Kalaburgi', 'Bailhongal']
            
        except Exception as e:
            st.error(f"Error loading data: {e}")
            self.results = {}
            self.models = None
            self.report = ""
    
    def main_dashboard(self):
        """Enhanced main dashboard page"""
        st.title("üå± Enhanced Soybean Market Analysis Dashboard")
        st.markdown("### Comprehensive Analysis with Multiple ML Models (Classification & Regression) and Detailed Cointegration (Weekly + VECM)")
        
        # Executive Summary Cards
        if 'descriptive_stats' in self.results:
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            
            total_records = sum(stats['Count'] for stats in self.results['descriptive_stats'].values())
            avg_price = np.mean([stats['Mean_Price'] for stats in self.results['descriptive_stats'].values()])
            highest_market = max(self.results['descriptive_stats'].items(), key=lambda x: x[1]['Mean_Price'])[0]
            markets_analyzed = len(self.results['descriptive_stats'])
            
            # Calculate total ML models (classification + regression)
            total_ml_models = 0
            if 'ml_models' in self.results:
                for model_type in self.results['ml_models']:
                    total_ml_models += len([m for m in self.results['ml_models'][model_type] if self.results['ml_models'][model_type][m] is not None])
            
            with col1:
                st.markdown(f"""
                <div class="metric-card">
                    <h3>üìä Total Records</h3>
                    <h2>{total_records:,}</h2>
                    <p>Data points analyzed</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-card">
                    <h3>üí∞ Average Price</h3>
                    <h2>‚Çπ{avg_price:.0f}</h2>
                    <p>Per quintal</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="metric-card">
                    <h3>üèÜ Top Market</h3>
                    <h2>{highest_market}</h2>
                    <p>Highest avg prices</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="metric-card">
                    <h3>üåæ Markets</h3>
                    <h2>{markets_analyzed}</h2>
                    <p>Analyzed</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col5:
                st.markdown(f"""
                <div class="metric-card">
                    <h3>ü§ñ ML Models</h3>
                    <h2>{total_ml_models}</h2>
                    <p>Total (Class + Reg)</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col6:
                if 'regression_comparisons' in self.results:
                    r2s = [comp['best_r2'] for comp in self.results['regression_comparisons'].values() if 'best_r2' in comp]
                    avg_r2 = np.mean(r2s) if r2s else 0
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>üìà Avg R¬≤</h3>
                        <h2>{avg_r2:.2f}</h2>
                        <p>Regression Performance</p>
                    </div>
                    """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Enhanced Key Findings
        st.subheader("üîç Enhanced Key Findings")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Market Integration Finding
            if 'cointegration_tables' in self.results:
                coint_tables = self.results['cointegration_tables']
                summary = coint_tables['summary_stats']
                coint_relations = summary['Number_of_Cointegrating_Relations']
                st.markdown(f"""
                <div class="alert-info">
                    <h4>üìà Market Integration Analysis (Weekly Data)</h4>
                    <p>Comprehensive Johansen cointegration test reveals <strong>{coint_relations} cointegrating relationship(s)</strong> 
                    among the five markets, indicating {'strong' if coint_relations > 1 else 'moderate' if coint_relations == 1 else 'weak'} market integration.</p>
                    <p><strong>Implication:</strong> {'Markets are highly integrated with rapid price transmission' if coint_relations > 1 else 'Markets show moderate integration with some price linkages' if coint_relations == 1 else 'Markets operate relatively independently'}</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Best ARIMA Model
            if 'arima_models' in self.results:
                best_arima = min(self.results['arima_models'].items(), key=lambda x: x[1]['aic'])
                market, model_info = best_arima
                st.markdown(f"""
                <div class="alert-success">
                    <h4>üéØ Best ARIMA Forecasting Model</h4>
                    <p><strong>{market} market</strong> with ARIMA{model_info['best_params']} 
                    achieving AIC of {model_info['aic']:.2f} for reliable price predictions.</p>
                    <p><strong>Model tested:</strong> {len(model_info.get('models_tested', []))} combinations evaluated</p>
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            # ML Models Performance (Classification)
            if 'model_comparisons' in self.results:
                st.markdown("**ü§ñ Classification Model Performance:**")
                
                all_accuracies = []
                for market, comp in self.results['model_comparisons'].items():
                    all_accuracies.extend([acc for _, acc, _ in comp['ranking']])
                
                avg_accuracy = np.mean(all_accuracies) if all_accuracies else 0
                
                st.write(f"üìä **Average Accuracy**: {avg_accuracy:.1%}")
                
                # Show best models by market
                for market, comp in list(self.results['model_comparisons'].items())[:3]:  # Show top 3 markets
                    best_model = comp['best_model']
                    best_acc = comp['best_accuracy']
                    color = "üü¢" if best_acc > 0.65 else "üü°" if best_acc > 0.55 else "üî¥"
                    st.write(f"{color} **{market}**: {best_model} ({best_acc:.1%})")
            
            # Regression Performance
            if 'regression_comparisons' in self.results:
                st.markdown("**üìà Regression Model Performance:**")
                
                all_r2s = [comp['best_r2'] for comp in self.results['regression_comparisons'].values()]
                avg_r2 = np.mean(all_r2s) if all_r2s else 0
                
                st.write(f"üìä **Average R¬≤**: {avg_r2:.3f}")
                
                for market, comp in list(self.results['regression_comparisons'].items())[:3]:
                    best_model = comp['best_model']
                    best_r2 = comp['best_r2']
                    color = "üü¢" if best_r2 > 0.5 else "üü°" if best_r2 > 0.3 else "üî¥"
                    st.write(f"{color} **{market}**: {best_model} (R¬≤={best_r2:.3f})")
        
        # Interactive Market Comparison
        st.subheader("üìä Enhanced Interactive Market Analysis")
        
        if 'descriptive_stats' in self.results:
            # Create enhanced comparison data
            markets_data = []
            for market, stats in self.results['descriptive_stats'].items():
                markets_data.append({
                    'Market': market,
                    'Average Price': stats['Mean_Price'],
                    'Price Volatility': stats['Std_Price'],
                    'CV (%)': (stats['Std_Price'] / stats['Mean_Price']) * 100,
                    'Average Arrivals': stats['Mean_Arrivals'],
                    'Max Price': stats['Max_Price'],
                    'Min Price': stats['Min_Price'],
                    'Skewness': stats['Skewness_Price'],
                    'Kurtosis': stats['Kurtosis_Price'],
                    'Sample Size': stats['Count']
                })
            
            df_markets = pd.DataFrame(markets_data)
            
            # Enhanced price comparison with volatility
            fig_enhanced = px.scatter(df_markets, x='Average Price', y='CV (%)',
                                    size='Sample Size', color='Market',
                                    title='Market Risk-Return Profile (CV = Coefficient of Variation)',
                                    hover_data=['Average Arrivals', 'Max Price', 'Min Price'],
                                    labels={'CV (%)': 'Risk (CV %)', 'Average Price': 'Return (Avg Price ‚Çπ)'})
            
            fig_enhanced.add_hline(y=df_markets['CV (%)'].mean(), line_dash="dash", 
                                 annotation_text="Average Risk Level", line_color="red")
            fig_enhanced.add_vline(x=df_markets['Average Price'].mean(), line_dash="dash", 
                                 annotation_text="Average Price", line_color="blue")
            
            fig_enhanced.update_layout(height=500)
            st.plotly_chart(fig_enhanced, use_container_width=True)
            
            # Table for Risk-Return Profile
            st.subheader("üìã Market Risk-Return Profile Table")
            risk_return_df = df_markets[['Market', 'Average Price', 'CV (%)', 'Sample Size', 'Average Arrivals']].copy()
            risk_return_df['Average Price'] = risk_return_df['Average Price'].round(2)
            risk_return_df['CV (%)'] = risk_return_df['CV (%)'].round(2)
            st.dataframe(risk_return_df, use_container_width=True)
            
            # Distribution analysis
            col1, col2 = st.columns(2)
            
            with col1:
                fig_dist = px.bar(df_markets, x='Market', y='Skewness',
                                title='Price Distribution Skewness',
                                color='Skewness',
                                color_continuous_scale='RdBu_r')
                fig_dist.add_hline(y=0, line_dash="dash", line_color="black")
                fig_dist.update_layout(height=400)
                st.plotly_chart(fig_dist, use_container_width=True)
                
                # Table for Skewness
                st.subheader("üìã Skewness Table")
                skewness_df = df_markets[['Market', 'Skewness']].copy()
                skewness_df['Skewness'] = skewness_df['Skewness'].round(3)
                st.dataframe(skewness_df, use_container_width=True)
            
            with col2:
                fig_kurt = px.bar(df_markets, x='Market', y='Kurtosis',
                                title='Price Distribution Kurtosis',
                                color='Kurtosis',
                                color_continuous_scale='Viridis')
                fig_kurt.add_hline(y=0, line_dash="dash", line_color="black")
                fig_kurt.update_layout(height=400)
                st.plotly_chart(fig_kurt, use_container_width=True)
                
                # Table for Kurtosis
                st.subheader("üìã Kurtosis Table")
                kurtosis_df = df_markets[['Market', 'Kurtosis']].copy()
                kurtosis_df['Kurtosis'] = kurtosis_df['Kurtosis'].round(3)
                st.dataframe(kurtosis_df, use_container_width=True)
    
    def enhanced_cointegration_analysis(self):
        """Enhanced cointegration analysis page with full VECM pipeline"""
        st.title("üîó Comprehensive Cointegration Analysis (Weekly Data + VECM Pipeline)")
        
        if 'cointegration_tables' in self.results:
            coint_tables = self.results['cointegration_tables']
            summary = coint_tables['summary_stats']
            
            # Test Summary
            st.markdown(f"""
            <div class="alert-info">
                <h4>üî¨ Johansen Cointegration Test Specifications</h4>
                <ul>
                    <li><strong>Markets Analyzed:</strong> {', '.join(summary['Markets_Analyzed'])}</li>
                    <li><strong>Number of Variables:</strong> {summary['Number_of_Variables']}</li>
                    <li><strong>Cointegrating Relations Found:</strong> {summary['Number_of_Cointegrating_Relations']}</li>
                    <li><strong>Data Frequency:</strong> Weekly</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            # Tabs for different steps
            tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "üìä Stationarity Tests", "‚è±Ô∏è Lag Selection", "üîÑ VAR Model", 
                "üìà Trace Statistics", "üìä Max Eigenvalue", "üî¢ VECM Results", "üìã Interpretation"
            ])
            
            with tab1:
                st.subheader("Step 1: Stationarity Tests (ADF on Weekly Prices)")
                
                if 'stationarity_table' in coint_tables:
                    stationarity_df = pd.DataFrame(coint_tables['stationarity_table'])
                    st.dataframe(stationarity_df, use_container_width=True)
                    
                    # Visualization
                    fig_adf = px.bar(stationarity_df, x='Market', y='ADF_Statistic',
                                   title='ADF Statistics (Lower = More Stationary)',
                                   color='Stationary_at_5%',
                                   color_discrete_map={'No (I(1))': 'red', 'Yes (I(0))': 'green'})
                    fig_adf.add_hline(y=stationarity_df['Critical_Value_5%'].mean(), line_dash="dash", line_color="black", annotation_text="Avg Critical Value")
                    fig_adf.update_layout(height=400)
                    st.plotly_chart(fig_adf, use_container_width=True)
                    
                    st.markdown("""
                    **üìñ Interpretation:** All series are I(1) (non-stationary in levels), suitable for cointegration.
                    """)
            
            with tab2:
                st.subheader("Step 2: Lag Length Selection (VAR Criteria)")
                
                if 'lag_table' in coint_tables:
                    lag_df = pd.DataFrame(coint_tables['lag_table'])
                    st.dataframe(lag_df, use_container_width=True)
                    
                    # Visualization
                    fig_lag = px.line(lag_df.melt(id_vars='Lag'), x='Lag', y='value', color='variable',
                                    title='Lag Selection Criteria (Lower = Better)',
                                    labels={'value': 'Criterion Value', 'variable': 'Criterion'})
                    fig_lag.update_layout(height=400)
                    st.plotly_chart(fig_lag, use_container_width=True)
                    
                    selected_lag = self.results.get('lag_selection', {}).get('selected_lag', 'N/A')
                    st.markdown(f"**Selected Lag:** {selected_lag} (AIC minimization)")
            
            with tab3:
                st.subheader("Step 3: VAR Model Summary")
                
                if 'var_summary' in self.results and 'table' in self.results['var_summary']:
                    var_df = pd.DataFrame(self.results['var_summary']['table'])
                    st.dataframe(var_df, use_container_width=True)
                    
                    # Visualization
                    fig_var = px.bar(var_df, x='Market', y='L1_Self_Coefficient',
                                   title='VAR L1 Self-Lag Coefficients (Momentum)',
                                   color='L1_Self_Coefficient', color_continuous_scale='RdBu_r')
                    fig_var.add_hline(y=0, line_dash="dash")
                    fig_var.update_layout(height=400)
                    st.plotly_chart(fig_var, use_container_width=True)
            
            with tab4:
                st.subheader("Step 4: Trace Statistics Test Results")
                
                # Create comprehensive trace statistics table
                trace_df = pd.DataFrame(coint_tables['trace_table'])
                
                # Format the dataframe for better display
                display_df = trace_df[['Null_Hypothesis', 'Alternative', 'Trace_Statistic', 
                                     'Critical_Value_5', 'Result_5']].copy()
                
                display_df.columns = ['Null Hypothesis', 'Alternative', 'Trace Statistic', 
                                    'Critical Value (5%)', 'Result']
                
                # Format numbers
                display_df['Trace Statistic'] = display_df['Trace Statistic'].apply(lambda x: f"{x:.4f}")
                display_df['Critical Value (5%)'] = display_df['Critical Value (5%)'].apply(lambda x: f"{x:.4f}")
                
                st.dataframe(display_df, use_container_width=True)
                
                # Visualization
                fig_trace = go.Figure()
                
                x_labels = [f"r ‚â§ {i}" for i in range(len(trace_df))]
                trace_stats = [float(x) for x in trace_df['Trace_Statistic'].values]
                critical_vals = [float(x) for x in trace_df['Critical_Value_5'].values]
                
                fig_trace.add_trace(go.Bar(
                    x=x_labels,
                    y=trace_stats,
                    name='Trace Statistic',
                    marker_color='lightblue'
                ))
                
                fig_trace.add_trace(go.Scatter(
                    x=x_labels,
                    y=critical_vals,
                    mode='lines+markers',
                    name='Critical Value (5%)',
                    line=dict(color='red', width=3)
                ))
                
                fig_trace.update_layout(
                    title='Trace Statistics vs Critical Values',
                    xaxis_title='Null Hypothesis',
                    yaxis_title='Statistic Value',
                    height=400
                )
                
                st.plotly_chart(fig_trace, use_container_width=True)
                
                # Explanation
                st.markdown("""
                **üìñ How to Read Trace Statistics:**
                - **Null Hypothesis (r ‚â§ k)**: At most k cointegrating relationships exist
                - **Reject H‚ÇÄ**: Evidence for more than k cointegrating relationships
                - **Accept H‚ÇÄ**: No evidence for more than k cointegrating relationships
                - **Decision Rule**: If Trace Statistic > Critical Value ‚Üí Reject H‚ÇÄ
                """)
            
            with tab5:
                st.subheader("Step 4: Maximum Eigenvalue Test Results")
                
                # Create maximum eigenvalue table
                eigen_df = pd.DataFrame(coint_tables['max_eigen_table'])
                
                display_df = eigen_df[['Null_Hypothesis', 'Alternative', 'Max_Eigen_Statistic', 
                                     'Critical_Value_5', 'Result_5']].copy()
                
                display_df.columns = ['Null Hypothesis', 'Alternative', 'Max Eigen Statistic', 
                                    'Critical Value (5%)', 'Result']
                
                # Format numbers
                display_df['Max Eigen Statistic'] = display_df['Max Eigen Statistic'].apply(lambda x: f"{x:.4f}")
                display_df['Critical Value (5%)'] = display_df['Critical Value (5%)'].apply(lambda x: f"{x:.4f}")
                
                st.dataframe(display_df, use_container_width=True)
                
                # Visualization
                fig_eigen = go.Figure()
                
                x_labels = [f"r = {i}" for i in range(len(eigen_df))]
                eigen_stats = [float(x) for x in eigen_df['Max_Eigen_Statistic'].values]
                critical_vals = [float(x) for x in eigen_df['Critical_Value_5'].values]
                
                fig_eigen.add_trace(go.Bar(
                    x=x_labels,
                    y=eigen_stats,
                    name='Max Eigen Statistic',
                    marker_color='lightgreen'
                ))
                
                fig_eigen.add_trace(go.Scatter(
                    x=x_labels,
                    y=critical_vals,
                    mode='lines+markers',
                    name='Critical Value (5%)',
                    line=dict(color='red', width=3)
                ))
                
                fig_eigen.update_layout(
                    title='Maximum Eigenvalue Statistics vs Critical Values',
                    xaxis_title='Null Hypothesis',
                    yaxis_title='Statistic Value',
                    height=400
                )
                
                st.plotly_chart(fig_eigen, use_container_width=True)
            
            with tab6:
                st.subheader("Step 5: VECM Model Results")
                
                if 'vecm_summary' in self.results:
                    vecm_summary = self.results['vecm_summary']
                    rank = vecm_summary['rank']
                    
                    st.markdown(f"**Cointegration Rank:** {rank}")
                    
                    # Beta vector
                    beta = vecm_summary['beta']
                    beta_df = pd.DataFrame({
                        'Market': self.markets[:len(beta)],
                        'Beta_Coefficient': [round(b, 4) for b in beta]
                    })
                    st.subheader("Cointegrating Vector (Beta, Normalized on First Market)")
                    st.dataframe(beta_df, use_container_width=True)
                    
                    # Alpha table
                    if 'alpha_table' in vecm_summary:
                        alpha_df = pd.DataFrame(vecm_summary['alpha_table'])
                        st.subheader("Adjustment Coefficients (Alpha)")
                        st.dataframe(alpha_df, use_container_width=True)
                        
                        # Visualization
                        fig_alpha = px.bar(alpha_df, x='Market', y='Alpha_Adjustment',
                                         title='Adjustment Speeds (Negative = Error Correction)',
                                         color='Significant_5%', color_discrete_map={'Yes': 'green', 'No': 'red'})
                        fig_alpha.add_hline(y=0, line_dash="dash")
                        fig_alpha.update_layout(height=400)
                        st.plotly_chart(fig_alpha, use_container_width=True)
            
            with tab7:
                st.subheader("Economic Interpretation")
                
                interpretation = coint_tables['interpretation']
                
                st.markdown(f"""
                <div class="alert-success">
                    <h4>üéØ {interpretation['conclusion']}</h4>
                    <p><strong>Economic Meaning:</strong> {interpretation['meaning']}</p>
                </div>
                """, unsafe_allow_html=True)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**üìà Market Implications:**")
                    for implication in interpretation['implications']:
                        st.write(f"‚Ä¢ {implication}")
                
                with col2:
                    st.markdown("**üèõÔ∏è Policy Implications:**")
                    for policy in interpretation['policy_implications']:
                        st.write(f"‚Ä¢ {policy}")
                
                # Additional insights
                st.markdown("---")
                st.subheader("üí° Strategic Insights")
                
                num_relations = summary['Number_of_Cointegrating_Relations']
                
                if num_relations == 0:
                    st.markdown("""
                    <div class="alert-warning">
                        <h5>‚ö†Ô∏è Independent Markets</h5>
                        <p><strong>Trading Strategy:</strong> Treat each market independently</p>
                        <p><strong>Risk Management:</strong> Diversification across markets may be effective</p>
                        <p><strong>Arbitrage Opportunities:</strong> May exist between markets</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                elif num_relations == 1:
                    st.markdown("""
                    <div class="alert-info">
                        <h5>üìä Moderate Integration</h5>
                        <p><strong>Trading Strategy:</strong> Consider inter-market relationships</p>
                        <p><strong>Risk Management:</strong> Some correlation risk exists</p>
                        <p><strong>Price Discovery:</strong> Information flows moderately between markets</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                else:
                    st.markdown("""
                    <div class="alert-success">
                        <h5>‚úÖ Strong Integration</h5>
                        <p><strong>Trading Strategy:</strong> Treat as integrated market system</p>
                        <p><strong>Risk Management:</strong> High correlation risk, limited diversification benefits</p>
                        <p><strong>Price Discovery:</strong> Rapid information transmission across markets</p>
                    </div>
                    """, unsafe_allow_html=True)
        
        else:
            st.warning("Cointegration analysis results not available.")
    
    def enhanced_arima_analysis(self):
        """Enhanced ARIMA analysis with detailed explanations"""
        st.title("üîÆ Enhanced ARIMA Forecasting with Model Selection Explanations")
        
        if 'arima_models' in self.results:
            # Market selection
            selected_market = st.selectbox("Select Market for Detailed Analysis:", 
                                         list(self.results['arima_models'].keys()))
            
            if selected_market in self.results['arima_models']:
                model_info = self.results['arima_models'][selected_market]
                
                # Model overview
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Selected Model", f"ARIMA{model_info['best_params']}")
                
                with col2:
                    st.metric("AIC Score", f"{model_info['aic']:.2f}")
                
                with col3:
                    st.metric("Parameters", f"{model_info['parameters_count']}")
                
                with col4:
                    st.metric("Log-Likelihood", f"{model_info['log_likelihood']:.2f}")
                
                # Detailed AIC Explanation
                if 'arima_explanations' in self.results and selected_market in self.results['arima_explanations']:
                    explanation = self.results['arima_explanations'][selected_market]
                    
                    st.subheader(f"üéØ Why ARIMA{model_info['best_params']} was Selected for {selected_market}")
                    
                    # Parameter interpretation
                    st.markdown("**üìä Parameter Interpretation:**")
                    p, d, q = model_info['best_params']
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown(f"""
                        <div class="alert-info">
                            <h5>AR(p={p})</h5>
                            <p>{'Uses past ' + str(p) + ' price values to predict current price' if p > 0 else 'No autoregressive component needed'}</p>
                            <p><strong>Meaning:</strong> {'Price momentum and trend patterns detected' if p > 0 else 'No momentum patterns'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"""
                        <div class="alert-info">
                            <h5>I(d={d})</h5>
                            <p>{'Data differenced ' + str(d) + ' time(s) to achieve stationarity' if d > 0 else 'Data is already stationary'}</p>
                            <p><strong>Meaning:</strong> {'Trend removal required' if d > 0 else 'No trend present'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(f"""
                        <div class="alert-info">
                            <h5>MA(q={q})</h5>
                            <p>{'Uses past ' + str(q) + ' forecast errors to improve predictions' if q > 0 else 'No moving average component needed'}</p>
                            <p><strong>Meaning:</strong> {'Error correction patterns detected' if q > 0 else 'No error patterns'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Model comparison
                    st.subheader("üìà Model Selection Process")
                    
                    if 'models_tested' in model_info:
                        models_tested = model_info['models_tested']
                        tested_combinations = len(models_tested)
                        successful_fits = len([m for m in models_tested if 'AIC' in m])
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Combinations Tested", tested_combinations)
                        
                        with col2:
                            st.metric("Successful Fits", successful_fits)
                        
                        with col3:
                            st.metric("Success Rate", f"{successful_fits/tested_combinations*100:.1f}%")
                        
                        with col4:
                            aic_values = [m['AIC'] for m in models_tested if 'AIC' in m]
                            if aic_values:
                                aic_range = max(aic_values) - min(aic_values)
                                st.metric("AIC Range", f"{aic_range:.1f}")
                    
                    # Top models comparison
                    if 'models_tested' in model_info and len(model_info['models_tested']) > 1:
                        st.subheader("üèÜ Top 10 Models Comparison")
                        
                        models_df = pd.DataFrame(model_info['models_tested'][:10])
                        models_df = models_df.sort_values('AIC').reset_index(drop=True)
                        models_df['Rank'] = range(1, len(models_df) + 1)
                        models_df['Model'] = models_df['order'].apply(lambda x: f'ARIMA({x[0]},{x[1]},{x[2]})')
                        models_df['ŒîAIC'] = models_df['AIC'] - models_df['AIC'].min()
                        
                        # Color code by performance
                        def color_delta_aic(val):
                            if val < 2:
                                return 'background-color: #d4edda'  # Green
                            elif val < 4:
                                return 'background-color: #fff3cd'  # Yellow
                            else:
                                return 'background-color: #f8d7da'  # Red
                        
                        styled_df = models_df[['Rank', 'Model', 'AIC', 'BIC', 'ŒîAIC']].style.applymap(
                            color_delta_aic, subset=['ŒîAIC'])
                        
                        st.dataframe(styled_df, use_container_width=True)
                        
                        # AIC comparison chart
                        fig_aic = px.bar(models_df.head(8), x='Model', y='ŒîAIC',
                                       title='Model Comparison (ŒîAIC from Best Model)',
                                       color='ŒîAIC',
                                       color_continuous_scale='RdYlGn_r')
                        fig_aic.add_hline(y=2, line_dash="dash", annotation_text="Substantial Support Threshold")
                        fig_aic.add_hline(y=4, line_dash="dash", annotation_text="Some Support Threshold")
                        fig_aic.update_layout(height=400)
                        st.plotly_chart(fig_aic, use_container_width=True)
                        
                        st.markdown("""
                        **üìñ AIC Interpretation Guide:**
                        - **ŒîAIC < 2**: Substantial support (alternative models are competitive)
                        - **2 ‚â§ ŒîAIC < 4**: Some support (alternative models have merit)
                        - **4 ‚â§ ŒîAIC < 7**: Little support (alternative models are weak)
                        - **ŒîAIC ‚â• 7**: No support (alternative models are poor)
                        """)
                
                # Forecasting section
                st.subheader("üìà Price Forecasts")
                
                if 'forecast' in model_info and model_info['forecast']:
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        # Forecast chart
                        months = list(range(1, len(model_info['forecast']) + 1))
                        fig_forecast = go.Figure()
                        
                        fig_forecast.add_trace(go.Scatter(
                            x=months,
                            y=model_info['forecast'],
                            mode='lines+markers',
                            name='Point Forecast',
                            line=dict(color='blue', width=3)
                        ))
                        
                        fig_forecast.update_layout(
                            title=f'{selected_market} Market - ARIMA{model_info["best_params"]} Forecast',
                            xaxis_title='Months Ahead',
                            yaxis_title='Price (‚Çπ/Quintal)',
                            height=400
                        )
                        
                        st.plotly_chart(fig_forecast, use_container_width=True)
                    
                    with col2:
                        st.markdown("**üìä Forecast Table:**")
                        
                        forecast_data = []
                        for i, price in enumerate(model_info['forecast'][:12], 1):
                            forecast_data.append({
                                'Month': i,
                                'Price (‚Çπ)': f'{price:.2f}'
                            })
                        
                        forecast_df = pd.DataFrame(forecast_data)
                        st.dataframe(forecast_df, use_container_width=True)
                
                # Model diagnostics
                st.subheader("üî¨ Model Diagnostics")
                
                diagnostic_col1, diagnostic_col2 = st.columns(2)
                
                with diagnostic_col1:
                    st.markdown("**‚úÖ Model Quality Indicators:**")
                    
                    aic_quality = "Excellent" if model_info['aic'] < 1200 else "Good" if model_info['aic'] < 1400 else "Fair"
                    params_complexity = "Simple" if model_info['parameters_count'] <= 3 else "Moderate" if model_info['parameters_count'] <= 5 else "Complex"
                    
                    st.write(f"‚Ä¢ **AIC Quality**: {aic_quality} ({model_info['aic']:.2f})")
                    st.write(f"‚Ä¢ **Model Complexity**: {params_complexity} ({model_info['parameters_count']} parameters)")
                    st.write(f"‚Ä¢ **Log-likelihood**: {model_info['log_likelihood']:.2f}")
                
                with diagnostic_col2:
                    st.markdown("**üìã Model Assumptions:**")
                    st.write("‚Ä¢ ‚úÖ Time series stationarity achieved")
                    st.write("‚Ä¢ ‚úÖ Residuals should be white noise")
                    st.write("‚Ä¢ ‚úÖ No remaining autocorrelation")
                    st.write("‚Ä¢ ‚ö†Ô∏è Assumes linear relationships")
            
            # Interactive forecast tool
            st.markdown("---")
            st.subheader("üõ†Ô∏è Interactive ARIMA Forecasting Tool")
            
            forecast_market = st.selectbox("Choose Market:", list(self.results['arima_models'].keys()), key='arima_forecast_tool')
            forecast_periods = st.slider("Forecast Periods (Months):", 1, 24, 6)
            
            if st.button("Generate ARIMA Forecast", type="primary"):
                if forecast_market in self.results['arima_models']:
                    model_info = self.results['arima_models'][forecast_market]
                    
                    # Use available forecast data
                    available_periods = min(forecast_periods, len(model_info.get('forecast', [])))
                    
                    if available_periods > 0:
                        st.success(f"Generated {available_periods}-month ARIMA forecast for {forecast_market}")
                        
                        # Display enhanced forecast
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            # Create forecast visualization
                            months = list(range(1, available_periods + 1))
                            forecasts = model_info['forecast'][:available_periods]
                            
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(
                                x=months, y=forecasts,
                                mode='lines+markers',
                                name=f'ARIMA{model_info["best_params"]} Forecast',
                                line=dict(color='purple', width=3)
                            ))
                            
                            fig.update_layout(
                                title=f'{forecast_market} - {available_periods} Month Forecast',
                                xaxis_title='Months Ahead',
                                yaxis_title='Price (‚Çπ/Quintal)',
                                height=400
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            # Forecast statistics
                            forecast_mean = np.mean(forecasts)
                            forecast_trend = "Increasing" if forecasts[-1] > forecasts[0] else "Decreasing" if forecasts[-1] < forecasts[0] else "Stable"
                            
                            st.markdown("**üìä Forecast Summary:**")
                            st.write(f"‚Ä¢ **Average Price**: ‚Çπ{forecast_mean:.2f}")
                            st.write(f"‚Ä¢ **Price Trend**: {forecast_trend}")
                            st.write(f"‚Ä¢ **Model Used**: ARIMA{model_info['best_params']}")
                            st.write(f"‚Ä¢ **Model AIC**: {model_info['aic']:.2f}")
                    else:
                        st.error("No forecast data available for this market.")
        
        else:
            st.warning("No ARIMA models available. Please run the analysis first.")
    
    def enhanced_ml_models(self):
        """Enhanced ML models page with forms for all three models (Classification & Regression)"""
        st.title("ü§ñ Enhanced Machine Learning Models")
        st.markdown("### Interactive Forms for Classification (Logistic Regression & Random Forest) and Regression (Linear Regression)")
        
        if 'ml_models' in self.results and any(self.results['ml_models'].values()):
            
            # Model comparison overview - Classification
            st.subheader("üìä Classification Model Performance Overview")
            
            if 'model_comparisons' in self.results:
                comparison_data = []
                for market, comp in self.results['model_comparisons'].items():
                    for rank, item in enumerate(comp['ranking'], 1):
                        if isinstance(item, (list, tuple)):
                            model_name = item[0]
                            accuracy = item[1]
                            cv_score = item[2]
                        else:
                            # Fallback assuming dict or other, but skip for now
                            continue
                        comparison_data.append({
                            'Market': market,
                            'Model': model_name,
                            'Test Accuracy': accuracy,
                            'CV Score': cv_score,
                            'Rank in Market': rank
                        })
                
                comparison_df = pd.DataFrame(comparison_data)
                
                # Performance visualization
                fig_performance = px.box(comparison_df, x='Model', y='Test Accuracy',
                                       title='Classification Model Performance Distribution Across Markets',
                                       color='Model')
                fig_performance.update_layout(height=400)
                st.plotly_chart(fig_performance, use_container_width=True)
                
                # Best models table
                st.subheader("üèÜ Best Classification Models by Market")
                best_models_data = []
                for market, comp in self.results['model_comparisons'].items():
                    if comp['ranking']:
                        item = comp['ranking'][0]
                        if isinstance(item, (list, tuple)):
                            best_model = item[0]
                            best_acc = item[1]
                            best_cv = item[2]
                        else:
                            best_model = comp['best_model']
                            best_acc = comp['best_accuracy']
                            best_cv = 0  # fallback
                        best_models_data.append({
                            'Market': market,
                            'Best Model': best_model,
                            'Accuracy': f"{best_acc:.1%}",
                            'CV Score': f"{best_cv:.1%}"
                        })
                
                best_models_df = pd.DataFrame(best_models_data)
                st.dataframe(best_models_df, use_container_width=True)
            
            # Regression Performance Overview
            st.subheader("üìà Regression Model Performance Overview")
            
            if 'regression_comparisons' in self.results:
                reg_comparison_data = []
                for market, comp in self.results['regression_comparisons'].items():
                    for rank, item in enumerate(comp['ranking'], 1):
                        if isinstance(item, (list, tuple)):
                            model_name = item[0]
                            r2 = item[1]
                            cv_score = item[2]
                        else:
                            continue
                        reg_comparison_data.append({
                            'Market': market,
                            'Model': model_name,
                            'Test R¬≤': r2,
                            'CV Score': cv_score,
                            'Rank in Market': rank
                        })
                
                reg_comparison_df = pd.DataFrame(reg_comparison_data)
                
                # Performance visualization
                fig_reg_performance = px.box(reg_comparison_df, x='Model', y='Test R¬≤',
                                           title='Regression Model Performance Distribution Across Markets',
                                           color='Model')
                fig_reg_performance.update_layout(height=400)
                st.plotly_chart(fig_reg_performance, use_container_width=True)
                
                # Best regression models table
                st.subheader("üèÜ Best Regression Models by Market")
                best_reg_data = []
                for market, comp in self.results['regression_comparisons'].items():
                    if comp['ranking']:
                        item = comp['ranking'][0]
                        if isinstance(item, (list, tuple)):
                            best_model = item[0]
                            best_r2 = item[1]
                            best_cv = item[2]
                        else:
                            best_model = comp['best_model']
                            best_r2 = comp['best_r2']
                            best_cv = 0
                        best_reg_data.append({
                            'Market': market,
                            'Best Model': best_model,
                            'R¬≤': f"{best_r2:.3f}",
                            'CV Score': f"{best_cv:.3f}"
                        })
                
                best_reg_df = pd.DataFrame(best_reg_data)
                st.dataframe(best_reg_df, use_container_width=True)
            
            # Interactive prediction forms
            st.markdown("---")
            st.subheader("üîÆ Interactive Prediction Forms")
            
            # Tabs for Classification and Regression
            tab_class, tab_reg = st.tabs(["üîÑ Classification (Direction)", "üìà Regression (Price Level)"])
            
            with tab_class:
                # Classification forms
                col1, col2 = st.columns(2)
                
                with col1:
                    available_markets_class = []
                    for model_type in ['logistic_regression', 'random_forest']:
                        if model_type in self.results['ml_models']:
                            available_markets_class.extend(self.results['ml_models'][model_type].keys())
                    available_markets_class = list(set(available_markets_class))
                    
                    selected_market_class = st.selectbox("Select Market:", available_markets_class, key="class_market")
                
                with col2:
                    available_models_class = []
                    if selected_market_class:
                        for model_type in ['logistic_regression', 'random_forest']:
                            if (model_type in self.results['ml_models'] and 
                                selected_market_class in self.results['ml_models'][model_type] and
                                self.results['ml_models'][model_type][selected_market_class] is not None):
                                available_models_class.append(model_type.replace('_', ' ').title())
                    
                    selected_model_type_class = st.selectbox("Select Model Type:", available_models_class, key="class_model")
                
                if selected_market_class and selected_model_type_class:
                    model_key = selected_model_type_class.lower().replace(' ', '_')
                    
                    if (model_key in self.results['ml_models'] and 
                        selected_market_class in self.results['ml_models'][model_key] and
                        self.results['ml_models'][model_key][selected_market_class] is not None):
                        
                        model_results = self.results['ml_models'][model_key][selected_market_class]
                        
                        # Model information
                        st.markdown(f"""
                        <div class="alert-info">
                            <h4>üìã {selected_model_type_class} Model for {selected_market_class}</h4>
                            <p><strong>Test Accuracy:</strong> {model_results['accuracy']:.1%}</p>
                            <p><strong>Cross-Validation Score:</strong> {model_results['cv_mean']:.1%} ¬± {model_results['cv_std']:.1%}</p>
                            <p><strong>Features Used:</strong> {len(model_results['feature_names'])} variables</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Prediction form
                        st.markdown(f"""
                        <div class="model-form">
                            <h4>üîÆ {selected_model_type_class} Prediction Form</h4>
                            <p>Enter market conditions to predict price movement direction</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Feature input form (same as before for classification)
                        feature_names = model_results['feature_names']
                        feature_values = {}
                        
                        # Create input fields based on feature names
                        col1, col2, col3 = st.columns(3)
                        
                        for i, feature in enumerate(feature_names):
                            col = [col1, col2, col3][i % 3]
                            
                            with col:
                                if 'Arrivals' in feature and 'MA' not in feature:
                                    if 'Lag' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (Tonnes):", 
                                            min_value=0.0, max_value=1000.0, 
                                            value=50.0, step=1.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                        )
                                    else:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (Tonnes):", 
                                            min_value=0.0, max_value=1000.0, 
                                            value=60.0, step=1.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                        )
                                elif 'Price' in feature:
                                    if 'Lag' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=1000.0, max_value=10000.0, 
                                            value=4000.0, step=10.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                        )
                                    elif 'MA' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=1000.0, max_value=10000.0, 
                                            value=4100.0, step=10.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                        )
                                    elif 'Volatility' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=0.0, max_value=2000.0, 
                                            value=100.0, step=1.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                        )
                                elif 'MA' in feature and 'Arrivals' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature} (Tonnes):", 
                                        min_value=0.0, max_value=1000.0, 
                                        value=55.0, step=1.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                    )
                                elif 'Month' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        min_value=1, max_value=12, 
                                        value=6, step=1, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                    )
                                elif 'Quarter' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        min_value=1, max_value=4, 
                                        value=2, step=1, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                    )
                                else:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        value=0.0, key=f"class_{feature}_{model_key}_{selected_market_class}"
                                    )
                        
                        # Prediction button for classification
                        if st.button(f"üéØ Predict Direction with {selected_model_type_class}", type="primary", key=f"class_predict_{model_key}_{selected_market_class}"):
                            
                            # Prepare feature vector
                            features_array = np.array([feature_values[feature] for feature in feature_names]).reshape(1, -1)
                            
                            # Simple prediction logic (simulation)
                            if model_key == 'logistic_regression' and 'coefficients' in model_results:
                                # Simulate logistic regression prediction
                                coefficients = model_results['coefficients']
                                # Normalize features (simple approximation)
                                features_normalized = (features_array - np.mean(features_array)) / (np.std(features_array) + 1e-8)
                                linear_combination = np.sum(features_normalized * coefficients)
                                probability = 1 / (1 + np.exp(-linear_combination))
                            
                            elif model_key == 'random_forest' and 'feature_importance' in model_results:
                                # Simulate tree-based model prediction
                                importances = model_results['feature_importance']
                                # Weighted average based on feature importance (approximation)
                                weighted_features = features_array[0] * importances
                                score = np.sum(weighted_features) / np.sum(importances)
                                probability = 1 / (1 + np.exp(-(score - 0.5) * 2))  # Simple sigmoid transformation
                            
                            else:
                                # Fallback: use model accuracy as base probability
                                probability = model_results['accuracy']
                            
                            # Ensure probability is in valid range
                            probability = max(0.1, min(0.9, probability))
                            
                            prediction = "üìà INCREASE" if probability > 0.5 else "üìâ DECREASE"  
                            confidence = max(probability, 1 - probability)
                            
                            # Display results
                            st.markdown(f"""
                            <div class="prediction-result">
                                <h4>üéØ {selected_model_type_class} Prediction Result</h4>
                                <p><strong>Market:</strong> {selected_market_class}</p>
                                <p><strong>Predicted Movement:</strong> {prediction}</p>
                                <p><strong>Confidence:</strong> {confidence:.1%}</p>
                                <p><strong>Probability of Increase:</strong> {probability:.1%}</p>
                                <p><strong>Model Accuracy:</strong> {model_results['accuracy']:.1%}</p>
                                <p><strong>Model Type:</strong> {selected_model_type_class}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Feature importance display (same as before)
                            if model_key == 'logistic_regression' and 'coefficients' in model_results:
                                st.subheader("üìä Feature Influence (Logistic Regression Coefficients)")
                                
                                coef_data = []
                                for feature, coef in zip(feature_names, model_results['coefficients']):
                                    coef_data.append({
                                        'Feature': feature,
                                        'Coefficient': coef,
                                        'Impact': 'Positive' if coef > 0 else 'Negative',
                                        'Magnitude': abs(coef)
                                    })
                                
                                coef_df = pd.DataFrame(coef_data).sort_values('Magnitude', ascending=False)
                                
                                fig_coef = px.bar(coef_df, x='Feature', y='Coefficient',
                                                title='Feature Coefficients (Impact on Price Increase)',
                                                color='Coefficient',
                                                color_continuous_scale='RdBu_r')
                                fig_coef.add_hline(y=0, line_dash="dash", line_color="black")
                                fig_coef.update_layout(height=400, xaxis_tickangle=-45)
                                st.plotly_chart(fig_coef, use_container_width=True)
                            
                            elif 'feature_importance' in model_results:
                                st.subheader("üìä Feature Importance")
                                
                                importance_data = []
                                for feature, importance in zip(feature_names, model_results['feature_importance']):
                                    importance_data.append({
                                        'Feature': feature,
                                        'Importance': importance
                                    })
                                
                                importance_df = pd.DataFrame(importance_data).sort_values('Importance', ascending=False)
                                
                                fig_importance = px.bar(importance_df, x='Feature', y='Importance',
                                                      title='Feature Importance in Model Decision',
                                                      color='Importance',
                                                      color_continuous_scale='Viridis')
                                fig_importance.update_layout(height=400, xaxis_tickangle=-45)
                                st.plotly_chart(fig_importance, use_container_width=True)
                
                # Classification Model comparison section
                st.markdown("---")
                st.subheader("üìà Detailed Classification Model Comparison")
                
                if selected_market_class:
                    available_model_results_class = {}
                    
                    for model_type in ['logistic_regression', 'random_forest']:
                        if (model_type in self.results['ml_models'] and 
                            selected_market_class in self.results['ml_models'][model_type] and
                            self.results['ml_models'][model_type][selected_market_class] is not None):
                            available_model_results_class[model_type] = self.results['ml_models'][model_type][selected_market_class]
                    
                    if available_model_results_class:
                        # Performance metrics comparison
                        metrics_data = []
                        for model_type, results in available_model_results_class.items():
                            metrics_data.append({
                                'Model': model_type.replace('_', ' ').title(),
                                'Test Accuracy': results['accuracy'],
                                'CV Mean': results['cv_mean'],
                                'CV Std': results['cv_std'],
                                'Stability': 'High' if results['cv_std'] < 0.05 else 'Medium' if results['cv_std'] < 0.1 else 'Low'
                            })
                        
                        metrics_df = pd.DataFrame(metrics_data)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.dataframe(metrics_df, use_container_width=True)
                        
                        with col2:
                            # Radar chart for model comparison
                            fig_radar = go.Figure()
                            
                            for _, row in metrics_df.iterrows():
                                fig_radar.add_trace(go.Scatterpolar(
                                    r=[row['Test Accuracy'], row['CV Mean'], 1-row['CV Std']],  # 1-CV_Std for stability
                                    theta=['Test Accuracy', 'CV Score', 'Stability'],
                                    fill='toself',
                                    name=row['Model']
                                ))
                            
                            fig_radar.update_layout(
                                polar=dict(
                                    radialaxis=dict(
                                        visible=True,
                                        range=[0, 1]
                                    )),
                                showlegend=True,
                                title=f"Classification Model Performance Comparison - {selected_market_class}",
                                height=400
                            )
                            
                            st.plotly_chart(fig_radar, use_container_width=True)
            
            with tab_reg:
                # Regression forms
                col1, col2 = st.columns(2)
                
                with col1:
                    available_markets_reg = []
                    for model_type in ['linear_regression']:
                        if model_type in self.results['ml_models']:
                            available_markets_reg.extend(self.results['ml_models'][model_type].keys())
                    available_markets_reg = list(set(available_markets_reg))
                    
                    selected_market_reg = st.selectbox("Select Market:", available_markets_reg, key="reg_market")
                
                with col2:
                    available_models_reg = []
                    if selected_market_reg:
                        for model_type in ['linear_regression']:
                            if (model_type in self.results['ml_models'] and 
                                selected_market_reg in self.results['ml_models'][model_type] and
                                self.results['ml_models'][model_type][selected_market_reg] is not None):
                                available_models_reg.append(model_type.replace('_', ' ').title())
                    
                    selected_model_type_reg = st.selectbox("Select Model Type:", available_models_reg, key="reg_model")
                
                if selected_market_reg and selected_model_type_reg:
                    model_key = selected_model_type_reg.lower().replace(' ', '_')
                    
                    if (model_key in self.results['ml_models'] and 
                        selected_market_reg in self.results['ml_models'][model_key] and
                        self.results['ml_models'][model_key][selected_market_reg] is not None):
                        
                        model_results = self.results['ml_models'][model_key][selected_market_reg]
                        
                        # Model information
                        st.markdown(f"""
                        <div class="alert-info">
                            <h4>üìã {selected_model_type_reg} Model for {selected_market_reg}</h4>
                            <p><strong>Test R¬≤ Score:</strong> {model_results['r2_score']:.3f}</p>
                            <p><strong>Cross-Validation Score:</strong> {model_results['cv_mean']:.3f} ¬± {model_results['cv_std']:.3f}</p>
                            <p><strong>Features Used:</strong> {len(model_results['feature_names'])} variables</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Prediction form for regression
                        st.markdown(f"""
                        <div class="model-form">
                            <h4>üîÆ {selected_model_type_reg} Prediction Form</h4>
                            <p>Enter market conditions to predict price level</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Feature input form (similar to classification)
                        feature_names = model_results['feature_names']
                        feature_values = {}
                        
                        col1, col2, col3 = st.columns(3)
                        
                        for i, feature in enumerate(feature_names):
                            col = [col1, col2, col3][i % 3]
                            
                            with col:
                                if 'Arrivals' in feature and 'MA' not in feature:
                                    if 'Lag' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (Tonnes):", 
                                            min_value=0.0, max_value=1000.0, 
                                            value=50.0, step=1.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                        )
                                    else:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (Tonnes):", 
                                            min_value=0.0, max_value=1000.0, 
                                            value=60.0, step=1.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                        )
                                elif 'Price' in feature:
                                    if 'Lag' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=1000.0, max_value=10000.0, 
                                            value=4000.0, step=10.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                        )
                                    elif 'MA' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=1000.0, max_value=10000.0, 
                                            value=4100.0, step=10.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                        )
                                    elif 'Volatility' in feature:
                                        feature_values[feature] = st.number_input(
                                            f"{feature} (‚Çπ):", 
                                            min_value=0.0, max_value=2000.0, 
                                            value=100.0, step=1.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                        )
                                elif 'MA' in feature and 'Arrivals' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature} (Tonnes):", 
                                        min_value=0.0, max_value=1000.0, 
                                        value=55.0, step=1.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                    )
                                elif 'Month' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        min_value=1, max_value=12, 
                                        value=6, step=1, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                    )
                                elif 'Quarter' in feature:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        min_value=1, max_value=4, 
                                        value=2, step=1, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                    )
                                else:
                                    feature_values[feature] = st.number_input(
                                        f"{feature}:", 
                                        value=0.0, key=f"reg_{feature}_{model_key}_{selected_market_reg}"
                                    )
                        
                        # Prediction button for regression
                        if st.button(f"üéØ Predict Price with {selected_model_type_reg}", type="primary", key=f"reg_predict_{model_key}_{selected_market_reg}"):
                            
                            # Prepare feature vector
                            features_array = np.array([feature_values[feature] for feature in feature_names]).reshape(1, -1)
                            
                            # Simple prediction logic for linear regression (simulation)
                            if model_key == 'linear_regression' and 'coefficients' in model_results and 'intercept' in model_results:
                                coefficients = model_results['coefficients']
                                intercept = model_results['intercept']
                                predicted_price = np.sum(features_array * coefficients) + intercept  # Fixed: intercept is scalar
                            else:
                                # Fallback: use average price or something
                                predicted_price = 4000.0
                            
                            # Display results
                            st.markdown(f"""
                            <div class="prediction-result">
                                <h4>üéØ {selected_model_type_reg} Prediction Result</h4>
                                <p><strong>Market:</strong> {selected_market_reg}</p>
                                <p><strong>Predicted Price:</strong> ‚Çπ{predicted_price:.2f} / Quintal</p>
                                <p><strong>Model R¬≤:</strong> {model_results['r2_score']:.3f}</p>
                                <p><strong>Model Type:</strong> {selected_model_type_reg} (Regression)</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Feature coefficients for linear regression
                            if model_key == 'linear_regression' and 'coefficients' in model_results:
                                st.subheader("üìä Feature Coefficients (Linear Regression)")
                                
                                coef_data = []
                                for feature, coef in zip(feature_names, model_results['coefficients']):
                                    coef_data.append({
                                        'Feature': feature,
                                        'Coefficient': coef,
                                        'Impact': 'Positive' if coef > 0 else 'Negative',
                                        'Magnitude': abs(coef)
                                    })
                                
                                coef_df = pd.DataFrame(coef_data).sort_values('Magnitude', ascending=False)
                                
                                fig_coef = px.bar(coef_df, x='Feature', y='Coefficient',
                                                title='Feature Coefficients (Impact on Price)',
                                                color='Coefficient',
                                                color_continuous_scale='RdBu_r')
                                fig_coef.add_hline(y=0, line_dash="dash", line_color="black")
                                fig_coef.update_layout(height=400, xaxis_tickangle=-45)
                                st.plotly_chart(fig_coef, use_container_width=True)
                
                # Regression Model comparison section
                st.markdown("---")
                st.subheader("üìà Detailed Regression Model Comparison")
                
                if selected_market_reg:
                    available_model_results_reg = {}
                    
                    for model_type in ['linear_regression']:
                        if (model_type in self.results['ml_models'] and 
                            selected_market_reg in self.results['ml_models'][model_type] and
                            self.results['ml_models'][model_type][selected_market_reg] is not None):
                            available_model_results_reg[model_type] = self.results['ml_models'][model_type][selected_market_reg]
                    
                    if available_model_results_reg:
                        # Performance metrics comparison
                        metrics_data = []
                        for model_type, results in available_model_results_reg.items():
                            metrics_data.append({
                                'Model': model_type.replace('_', ' ').title(),
                                'Test R¬≤': results['r2_score'],
                                'CV Mean': results['cv_mean'],
                                'CV Std': results['cv_std'],
                                'Stability': 'High' if results['cv_std'] < 0.05 else 'Medium' if results['cv_std'] < 0.1 else 'Low'
                            })
                        
                        metrics_df = pd.DataFrame(metrics_data)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.dataframe(metrics_df, use_container_width=True)
                        
                        with col2:
                            # Radar chart for model comparison (adapted for R2)
                            fig_radar = go.Figure()
                            
                            for _, row in metrics_df.iterrows():
                                fig_radar.add_trace(go.Scatterpolar(
                                    r=[row['Test R¬≤'], row['CV Mean'], 1-row['CV Std']],
                                    theta=['Test R¬≤', 'CV Score', 'Stability'],
                                    fill='toself',
                                    name=row['Model']
                                ))
                            
                            fig_radar.update_layout(
                                polar=dict(
                                    radialaxis=dict(
                                        visible=True,
                                        range=[0, 1]
                                    )),
                                showlegend=True,
                                title=f"Regression Model Performance Comparison - {selected_market_reg}",
                                height=400
                            )
                            
                            st.plotly_chart(fig_radar, use_container_width=True)
        
        else:
            st.warning("No ML model results available. Please run the enhanced analysis first.")
    
   
    def format_report_section(self, text):
        """Format report text for better Streamlit display"""
        # Convert text formatting
        formatted = text.replace("="*100, "---")
        formatted = formatted.replace("="*80, "---") 
        formatted = formatted.replace("="*60, "---")
        formatted = formatted.replace("="*50, "---")
        formatted = formatted.replace("-"*80, "")
        formatted = formatted.replace("-"*60, "")
        formatted = formatted.replace("-"*50, "")
        formatted = formatted.replace("-"*40, "")
        
        return formatted
    
    def create_summary_report(self):
        """Create a concise summary report"""
        summary = []
        summary.append("SOYBEAN MARKET ANALYSIS - EXECUTIVE SUMMARY")
        summary.append("="*50)
        
        # Key findings
        if 'descriptive_stats' in self.results:
            total_records = sum(stats['Count'] for stats in self.results['descriptive_stats'].values())
            summary.append(f"\nüìä DATA OVERVIEW:")
            summary.append(f"‚Ä¢ Total records analyzed: {total_records:,}")
            summary.append(f"‚Ä¢ Markets covered: {len(self.results['descriptive_stats'])}")
            
            # Best and worst performing markets
            markets_by_price = sorted(self.results['descriptive_stats'].items(), 
                                    key=lambda x: x[1]['Mean_Price'], reverse=True)
            summary.append(f"‚Ä¢ Highest prices: {markets_by_price[0][0]} (‚Çπ{markets_by_price[0][1]['Mean_Price']:.0f})")
            summary.append(f"‚Ä¢ Lowest prices: {markets_by_price[-1][0]} (‚Çπ{markets_by_price[-1][1]['Mean_Price']:.0f})")
        
        # Cointegration summary
        if 'cointegration_tables' in self.results:
            coint_relations = self.results['cointegration_tables']['summary_stats']['Number_of_Cointegrating_Relations']
            summary.append(f"\nüîó MARKET INTEGRATION (WEEKLY):")
            summary.append(f"‚Ä¢ Cointegrating relationships: {coint_relations}")
            summary.append(f"‚Ä¢ Integration level: {'Strong' if coint_relations > 1 else 'Moderate' if coint_relations == 1 else 'Weak'}")
        
        # Best models
        if 'arima_models' in self.results:
            best_arima = min(self.results['arima_models'].items(), key=lambda x: x[1]['aic'])
            summary.append(f"\nüìà FORECASTING:")
            summary.append(f"‚Ä¢ Best ARIMA model: {best_arima[0]} ARIMA{best_arima[1]['best_params']}")
            summary.append(f"‚Ä¢ Model quality: AIC {best_arima[1]['aic']:.1f}")
        
        if 'model_comparisons' in self.results:
            all_accuracies = []
            for comp in self.results['model_comparisons'].values():
                all_accuracies.extend([acc for _, acc, _ in comp['ranking']])
            avg_accuracy = np.mean(all_accuracies) if all_accuracies else 0
            
            summary.append(f"\nü§ñ CLASSIFICATION ML:")
            summary.append(f"‚Ä¢ Average accuracy: {avg_accuracy:.1%}")
            summary.append(f"‚Ä¢ Models evaluated: Logistic Regression, Random Forest")
        
        if 'regression_comparisons' in self.results:
            all_r2s = [comp['best_r2'] for comp in self.results['regression_comparisons'].values()]
            avg_r2 = np.mean(all_r2s) if all_r2s else 0
            
            summary.append(f"\nüìà REGRESSION ML:")
            summary.append(f"‚Ä¢ Average R¬≤: {avg_r2:.3f}")
            summary.append(f"‚Ä¢ Model evaluated: Linear Regression")
        
        # Recommendations
        summary.append(f"\nüí° KEY RECOMMENDATIONS:")
        summary.append("‚Ä¢ Use ARIMA models for medium-term price forecasting")
        summary.append("‚Ä¢ Apply classification ML models for daily price movement prediction")  
        summary.append("‚Ä¢ Use Linear Regression for price level predictions")
        summary.append("‚Ä¢ Consider market integration in trading strategies (from VECM)")
        summary.append("‚Ä¢ Implement risk management based on volatility patterns")
        
        return "\n".join(summary)

def main():
    """Main application function"""
    
    # Initialize enhanced dashboard
    dashboard = EnhancedSoybeanDashboard()
    
    # Sidebar navigation
    st.sidebar.title("üå± Enhanced Navigation")
    st.sidebar.markdown("---")
    
    pages = {
        "üè† Enhanced Dashboard": dashboard.main_dashboard,
        "üîó Cointegration Analysis": dashboard.enhanced_cointegration_analysis,
        "üîÆ ARIMA Forecasting": dashboard.enhanced_arima_analysis,
        "ü§ñ ML Models": dashboard.enhanced_ml_models,
       
    }
    
    selected_page = st.sidebar.selectbox("Choose Analysis:", list(pages.keys()))
    
    # Enhanced about section
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    ### üéØ Enhanced Analysis Features
    
    **New Additions:**
    - ‚úÖ Multiple ML Models (Logistic Regression, Random Forest - Classification)
    - ‚úÖ Linear Regression (Regression for Price Prediction)
    - ‚úÖ Comprehensive Cointegration Tables (Weekly + VECM Pipeline)  
    - ‚úÖ Detailed AIC Explanations
    - ‚úÖ Interactive Prediction Forms (Direction & Price Level)
    - ‚úÖ Enhanced Visualizations
    
    **Research Objectives:**
    1. Enhanced descriptive statistics
    2. Comprehensive Johansen cointegration (Weekly + Stationarity/Lag/VAR/VECM)
    3. ARIMA/SARIMA with model selection explanations
    4. Multiple ML models comparison (Class + Reg)
    
    **Markets Analyzed:**
    - Haveri
    - Kalagategi  
    - Bidar
    - Kalaburgi
    - Bailhongal
    
    **ML Models:**
    - üîµ Logistic Regression (Class)
    - üå≤ Random Forest (Class)
    - üìà Linear Regression (Reg)
    """)
    
    # Execute selected page
    pages[selected_page]()
    
    # Enhanced footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.8em;'>
        <p>üå± Enhanced Soybean Market Analysis Dashboard | Built with Advanced ML & Statistical Models</p>
        <p>Featuring: Logistic Regression ‚Ä¢ Random Forest ‚Ä¢ Linear Regression ‚Ä¢ Comprehensive Cointegration Analysis (Weekly VECM)</p>
        <p>For research and educational purposes | ¬© 2025</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":

    main()
