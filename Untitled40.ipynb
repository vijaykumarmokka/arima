{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Statistical and Time Series Libraries\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen, select_order, VECM\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "\n",
        "# Visualization Libraries\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "\n",
        "# Additional for JSON handling\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "class SimplifiedEnhancedSoybeanAnalysis:\n",
        "    \"\"\"\n",
        "    Simplified Enhanced Comprehensive Soybean Market Analysis System\n",
        "\n",
        "    Features:\n",
        "    1. Descriptive Statistics, Correlation & Regression\n",
        "    2. Comprehensive Johansen Co-integration Test (Updated: Weekly Data + Full VECM Pipeline)\n",
        "    3. ARIMA/SARIMA with detailed AIC explanation\n",
        "    4. Multiple ML Models: Logistic Regression, Random Forest, Linear Regression\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data = {}\n",
        "        self.markets = ['Haveri', 'Kalagategi', 'Bidar', 'Kalaburgi', 'Bailhongal']\n",
        "        self.results = {\n",
        "            'descriptive_stats': {},\n",
        "            'correlation_matrix': None,\n",
        "            'regression_results': {},\n",
        "            'cointegration_results': {},\n",
        "            'cointegration_tables': {},\n",
        "            'arima_models': {},\n",
        "            'arima_explanations': {},\n",
        "            'forecasts': {},\n",
        "            'ml_models': {\n",
        "                'logistic_regression': {},\n",
        "                'random_forest': {},\n",
        "                'linear_regression': {}\n",
        "            },\n",
        "            'model_comparisons': {},\n",
        "            'regression_comparisons': {}\n",
        "        }\n",
        "\n",
        "    def load_real_data(self):\n",
        "        \"\"\"Load real datasets from Excel files in /content/\"\"\"\n",
        "        print(\"Loading real data from Excel files in /content/...\")\n",
        "\n",
        "        market_files = {\n",
        "            'Haveri': '/content/haveri.xlsx',\n",
        "            'Kalagategi': '/content/kalagategi.xlsx',\n",
        "            'Bidar': '/content/Bidar.xlsx',\n",
        "            'Kalaburgi': '/content/kalaburgi.xlsx',\n",
        "            'Bailhongal': '/content/bailhongal.xlsx'\n",
        "        }\n",
        "\n",
        "        for market, file_path in market_files.items():\n",
        "            try:\n",
        "                # Read the specific sheet with header=1 (skipping title row)\n",
        "                df = pd.read_excel(file_path, header=1, sheet_name='Agmarknet_Price_And_Arrival_Rep')\n",
        "\n",
        "                # Filter to Soyabeen variety only\n",
        "                df = df[df['Variety'] == 'Soyabeen'].copy()\n",
        "\n",
        "                if len(df) == 0:\n",
        "                    raise ValueError(\"No Soyabeen data found\")\n",
        "\n",
        "                # Handle date conversion\n",
        "                if pd.api.types.is_numeric_dtype(df['Reported Date']):\n",
        "                    df['Reported Date'] = pd.to_datetime(df['Reported Date'], origin='1899-12-30')\n",
        "                else:\n",
        "                    df['Reported Date'] = pd.to_datetime(df['Reported Date'])\n",
        "\n",
        "                # Sort by date\n",
        "                df = df.sort_values('Reported Date').reset_index(drop=True)\n",
        "\n",
        "                self.data[market] = df\n",
        "                print(f\"âœ“ Loaded {market} data from {file_path}: {len(df)} Soyabeen records (date range: {df['Reported Date'].min().date()} to {df['Reported Date'].max().date()})\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"âœ— File {file_path} not found - skipping {market}\")\n",
        "                self.data[market] = pd.DataFrame()\n",
        "            except Exception as e:\n",
        "                print(f\"âœ— Error loading {file_path}: {e} - skipping {market}\")\n",
        "                self.data[market] = pd.DataFrame()\n",
        "\n",
        "    def objective_1_descriptive_analysis(self):\n",
        "        \"\"\"Enhanced descriptive statistics analysis\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"OBJECTIVE 1: ENHANCED DESCRIPTIVE STATISTICS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                df = self.data[market]\n",
        "                if 'Modal Price (Rs./Quintal)' not in df.columns or 'Arrivals (Tonnes)' not in df.columns:\n",
        "                    print(f\"Warning: Required columns missing in {market} - skipping stats.\")\n",
        "                    continue\n",
        "\n",
        "                stats_data = {\n",
        "                    'Market': market,\n",
        "                    'Count': len(df),\n",
        "                    'Mean_Price': df['Modal Price (Rs./Quintal)'].mean(),\n",
        "                    'Std_Price': df['Modal Price (Rs./Quintal)'].std(),\n",
        "                    'Min_Price': df['Modal Price (Rs./Quintal)'].min(),\n",
        "                    'Max_Price': df['Modal Price (Rs./Quintal)'].max(),\n",
        "                    'Mean_Arrivals': df['Arrivals (Tonnes)'].mean(),\n",
        "                    'Std_Arrivals': df['Arrivals (Tonnes)'].std(),\n",
        "                    'Min_Arrivals': df['Arrivals (Tonnes)'].min(),\n",
        "                    'Max_Arrivals': df['Arrivals (Tonnes)'].max(),\n",
        "                    'Median_Price': df['Modal Price (Rs./Quintal)'].median(),\n",
        "                    'IQR_Price': df['Modal Price (Rs./Quintal)'].quantile(0.75) - df['Modal Price (Rs./Quintal)'].quantile(0.25),\n",
        "                    'Skewness_Price': df['Modal Price (Rs./Quintal)'].skew(),\n",
        "                    'Kurtosis_Price': df['Modal Price (Rs./Quintal)'].kurtosis(),\n",
        "                    'CV_Price': (df['Modal Price (Rs./Quintal)'].std() / df['Modal Price (Rs./Quintal)'].mean()) * 100\n",
        "                }\n",
        "\n",
        "                self.results['descriptive_stats'][market] = stats_data\n",
        "\n",
        "                print(f\"\\n{market} Market Summary:\")\n",
        "                print(f\"  Records: {stats_data['Count']:,}\")\n",
        "                print(f\"  Price (Rs/Qt): {stats_data['Mean_Price']:.2f} Â± {stats_data['Std_Price']:.2f}\")\n",
        "                print(f\"  CV: {stats_data['CV_Price']:.1f}%\")\n",
        "                print(f\"  Skewness: {stats_data['Skewness_Price']:.3f}\")\n",
        "            else:\n",
        "                print(f\"\\n{market}: No data loaded - skipping.\")\n",
        "\n",
        "        # Correlation analysis\n",
        "        self.correlation_analysis()\n",
        "\n",
        "    def correlation_analysis(self):\n",
        "        \"\"\"Perform correlation analysis\"\"\"\n",
        "        print(\"\\n\" + \"-\"*40)\n",
        "        print(\"CORRELATION ANALYSIS\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "        correlation_data = []\n",
        "\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                df = self.data[market]\n",
        "                if 'Modal Price (Rs./Quintal)' in df.columns and 'Arrivals (Tonnes)' in df.columns:\n",
        "                    corr = df['Modal Price (Rs./Quintal)'].corr(df['Arrivals (Tonnes)'])\n",
        "                    correlation_data.append({\n",
        "                        'Market': market,\n",
        "                        'Price_Arrivals_Correlation': corr\n",
        "                    })\n",
        "                    print(f\"{market}: Price-Arrivals Correlation = {corr:.4f}\")\n",
        "                else:\n",
        "                    print(f\"{market}: Required columns missing - skipping correlation.\")\n",
        "            else:\n",
        "                print(f\"{market}: No data - skipping correlation.\")\n",
        "\n",
        "        self.results['correlation_data'] = correlation_data\n",
        "\n",
        "    def objective_2_comprehensive_cointegration_analysis(self):\n",
        "        \"\"\"Comprehensive Johansen cointegration test with full VECM pipeline (Weekly Data) - FULLY FIXED VERSION\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"OBJECTIVE 2: COMPREHENSIVE JOHANSEN CO-INTEGRATION (WEEKLY DATA + FULL VECM PIPELINE)\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Prepare price data (WEEKLY resampling) - FIX: Use forward fill to preserve data\n",
        "        price_data = pd.DataFrame()\n",
        "        loaded_markets = []\n",
        "\n",
        "        # First, find the common date range across all markets\n",
        "        min_date = None\n",
        "        max_date = None\n",
        "\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                df = self.data[market]\n",
        "                if 'Modal Price (Rs./Quintal)' in df.columns:\n",
        "                    if min_date is None or df['Reported Date'].min() > min_date:\n",
        "                        min_date = df['Reported Date'].min()\n",
        "                    if max_date is None or df['Reported Date'].max() < max_date:\n",
        "                        max_date = df['Reported Date'].max()\n",
        "\n",
        "        print(f\"Common date range: {min_date.date() if min_date else 'N/A'} to {max_date.date() if max_date else 'N/A'}\")\n",
        "\n",
        "        # Now resample each market's data and forward-fill missing values\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                df = self.data[market]\n",
        "                if 'Modal Price (Rs./Quintal)' in df.columns:\n",
        "                    # Set index and resample\n",
        "                    market_series = df.set_index('Reported Date')['Modal Price (Rs./Quintal)']\n",
        "\n",
        "                    # Resample to weekly, using mean for the week\n",
        "                    weekly_data = market_series.resample('W').mean()\n",
        "\n",
        "                    # Forward fill missing values (up to 4 weeks)\n",
        "                    weekly_data = weekly_data.ffill(limit=4)\n",
        "\n",
        "                    # Filter to common date range\n",
        "                    if min_date and max_date:\n",
        "                        weekly_data = weekly_data[(weekly_data.index >= min_date) & (weekly_data.index <= max_date)]\n",
        "\n",
        "                    price_data[market] = weekly_data\n",
        "                    loaded_markets.append(market)\n",
        "\n",
        "        # Now drop any remaining NaN rows\n",
        "        initial_rows = len(price_data)\n",
        "        price_data = price_data.dropna()\n",
        "        final_rows = len(price_data)\n",
        "\n",
        "        print(f\"âœ“ Prepared weekly price data for {len(loaded_markets)} markets\")\n",
        "        print(f\"  Initial observations: {initial_rows}, After dropna: {final_rows}\")\n",
        "\n",
        "        if len(price_data.columns) >= 2 and len(price_data) >= 20:\n",
        "            try:\n",
        "                # Initialize cointegration_tables structure\n",
        "                self.results['cointegration_tables'] = {\n",
        "                    'stationarity_table': [],\n",
        "                    'lag_table': [],\n",
        "                    'trace_table': [],\n",
        "                    'max_eigen_table': [],\n",
        "                    'summary_stats': {},\n",
        "                    'interpretation': {}\n",
        "                }\n",
        "\n",
        "                # Step 1: Stationarity Tests (ADF on levels)\n",
        "                print(\"Step 1: Performing stationarity tests...\")\n",
        "                stationarity_table = []\n",
        "                for market in price_data.columns:\n",
        "                    adf_result = adfuller(price_data[market])\n",
        "                    stationarity_table.append({\n",
        "                        'Market': market,\n",
        "                        'ADF_Statistic': round(float(adf_result[0]), 4),\n",
        "                        'p_value': round(float(adf_result[1]), 4),\n",
        "                        'Stationary_at_5%': 'No (I(1))' if adf_result[1] > 0.05 else 'Yes (I(0))',\n",
        "                        'Critical_Value_5%': round(float(adf_result[4]['5%']), 4)\n",
        "                    })\n",
        "\n",
        "                self.results['cointegration_tables']['stationarity_table'] = stationarity_table\n",
        "                print(f\"âœ“ Stationarity tests completed for {len(stationarity_table)} markets\")\n",
        "\n",
        "                # Step 2: Lag Length Selection for VAR - FULLY FIXED VERSION\n",
        "                print(\"Step 2: Selecting optimal lag length...\")\n",
        "                maxlags = min(12, int(len(price_data) / (len(price_data.columns) * 3)))\n",
        "\n",
        "                if maxlags < 1:\n",
        "                    maxlags = 1\n",
        "\n",
        "                selected_lag = 1  # Default\n",
        "                lag_table = []\n",
        "\n",
        "                try:\n",
        "                    # Fit VAR models manually for each lag to get criteria\n",
        "                    var_model = VAR(price_data)\n",
        "\n",
        "                    for lag in range(1, min(maxlags + 1, 13)):\n",
        "                        try:\n",
        "                            if len(price_data) > lag * len(price_data.columns) + 10:\n",
        "                                var_fitted = var_model.fit(lag, trend='c')\n",
        "                                lag_table.append({\n",
        "                                    'Lag': lag,\n",
        "                                    'AIC': round(float(var_fitted.aic), 2),\n",
        "                                    'BIC': round(float(var_fitted.bic), 2),\n",
        "                                    'HQIC': round(float(var_fitted.hqic), 2),\n",
        "                                    'FPE': round(float(var_fitted.fpe), 5)\n",
        "                                })\n",
        "                            else:\n",
        "                                break\n",
        "                        except Exception as e:\n",
        "                            print(f\"  âš  Could not fit VAR with lag {lag}: {e}\")\n",
        "                            continue\n",
        "\n",
        "                    # Select lag with minimum AIC\n",
        "                    if lag_table:\n",
        "                        min_aic_entry = min(lag_table, key=lambda x: x['AIC'])\n",
        "                        selected_lag = min_aic_entry['Lag']\n",
        "                        print(f\"âœ“ Tested {len(lag_table)} lag orders\")\n",
        "                    else:\n",
        "                        print(\"âš  Could not compute lag selection criteria, using default lag=1\")\n",
        "                        lag_table = [{'Lag': 1, 'AIC': np.nan, 'BIC': np.nan, 'HQIC': np.nan, 'FPE': np.nan}]\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âš  Lag selection failed: {e}. Using default lag=1\")\n",
        "                    lag_table = [{'Lag': 1, 'AIC': np.nan, 'BIC': np.nan, 'HQIC': np.nan, 'FPE': np.nan}]\n",
        "\n",
        "                self.results['cointegration_tables']['lag_table'] = lag_table\n",
        "                self.results['lag_selection'] = {'selected_lag': int(selected_lag)}\n",
        "                print(f\"âœ“ Selected lag: {selected_lag}\")\n",
        "\n",
        "                # Step 3: Fit VAR Model\n",
        "                print(\"Step 3: Fitting VAR model...\")\n",
        "                if len(price_data) > selected_lag + 10:\n",
        "                    try:\n",
        "                        var_model = VAR(price_data)\n",
        "                        var_fitted = var_model.fit(selected_lag, trend='c')\n",
        "\n",
        "                        # Create VAR summary table\n",
        "                        var_table = []\n",
        "                        for i, market in enumerate(price_data.columns):\n",
        "                            try:\n",
        "                                # Get parameters for this market equation\n",
        "                                params = var_fitted.params.iloc[:, i]\n",
        "                                intercept = float(params.iloc[0])\n",
        "\n",
        "                                # Get L1 self-coefficient (coefficient of market's own lag 1)\n",
        "                                # In VAR params, after intercept, coefficients are organized as:\n",
        "                                # [lag1_market1, lag1_market2, ..., lag2_market1, lag2_market2, ...]\n",
        "                                l1_self_idx = 1 + i  # intercept + position in first lag block\n",
        "\n",
        "                                if l1_self_idx < len(params):\n",
        "                                    self_lag_l1 = float(params.iloc[l1_self_idx])\n",
        "                                else:\n",
        "                                    self_lag_l1 = 0.0\n",
        "\n",
        "                                var_table.append({\n",
        "                                    'Market': market,\n",
        "                                    'Intercept': round(intercept, 2),\n",
        "                                    'L1_Self_Coefficient': round(self_lag_l1, 4)\n",
        "                                })\n",
        "                            except Exception as e:\n",
        "                                print(f\"  âš  Error extracting VAR params for {market}: {e}\")\n",
        "                                var_table.append({\n",
        "                                    'Market': market,\n",
        "                                    'Intercept': np.nan,\n",
        "                                    'L1_Self_Coefficient': np.nan\n",
        "                                })\n",
        "\n",
        "                        self.results['var_summary'] = {'table': var_table}\n",
        "                        print(f\"âœ“ VAR model fitted\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš  VAR fitting failed: {e}\")\n",
        "                        self.results['var_summary'] = {'table': []}\n",
        "                else:\n",
        "                    self.results['var_summary'] = {'table': []}\n",
        "                    print(\"âš  Insufficient data for VAR model\")\n",
        "\n",
        "                # Step 4: Johansen Cointegration Test\n",
        "                print(\"Step 4: Performing Johansen cointegration test...\")\n",
        "                johansen_result = coint_johansen(price_data, det_order=0, k_ar_diff=max(0, selected_lag-1))\n",
        "\n",
        "                # Create trace statistics table\n",
        "                trace_table = []\n",
        "                for i, (stat, cv) in enumerate(zip(johansen_result.lr1, johansen_result.cvt)):\n",
        "                    trace_table.append({\n",
        "                        'Null_Hypothesis': f'r â‰¤ {i}',\n",
        "                        'Alternative': f'r > {i}',\n",
        "                        'Trace_Statistic': round(float(stat), 4),\n",
        "                        'Critical_Value_5': round(float(cv[1]), 4),\n",
        "                        'Result_5': 'Reject H0' if stat > cv[1] else 'Accept H0'\n",
        "                    })\n",
        "\n",
        "                # Create max eigenvalue table\n",
        "                max_eigen_table = []\n",
        "                for i, (stat, cv) in enumerate(zip(johansen_result.lr2, johansen_result.cvm)):\n",
        "                    max_eigen_table.append({\n",
        "                        'Null_Hypothesis': f'r = {i}',\n",
        "                        'Alternative': f'r = {i+1}',\n",
        "                        'Max_Eigen_Statistic': round(float(stat), 4),\n",
        "                        'Critical_Value_5': round(float(cv[1]), 4),\n",
        "                        'Result_5': 'Reject H0' if stat > cv[1] else 'Accept H0'\n",
        "                    })\n",
        "\n",
        "                # Calculate number of cointegrating relations\n",
        "                num_coint_relations = sum(1 for i, (stat, cv) in enumerate(zip(johansen_result.lr1, johansen_result.cvt)) if stat > cv[1])\n",
        "\n",
        "                # Summary statistics\n",
        "                summary_stats = {\n",
        "                    'Number_of_Variables': int(len(price_data.columns)),\n",
        "                    'Markets_Analyzed': list(price_data.columns),\n",
        "                    'Eigenvalues': [round(float(e), 4) for e in johansen_result.eig],\n",
        "                    'Number_of_Cointegrating_Relations': int(num_coint_relations)\n",
        "                }\n",
        "\n",
        "                # Update cointegration_tables\n",
        "                self.results['cointegration_tables'].update({\n",
        "                    'trace_table': trace_table,\n",
        "                    'max_eigen_table': max_eigen_table,\n",
        "                    'summary_stats': summary_stats,\n",
        "                    'interpretation': self.generate_cointegration_interpretation(num_coint_relations)\n",
        "                })\n",
        "\n",
        "                print(f\"âœ“ Johansen test completed: {num_coint_relations} cointegrating relation(s)\")\n",
        "\n",
        "                # Step 5: Fit VECM (based on rank from Johansen)\n",
        "                print(\"Step 5: Fitting VECM model...\")\n",
        "                rank = num_coint_relations\n",
        "\n",
        "                if rank > 0 and rank < len(price_data.columns):\n",
        "                    try:\n",
        "                        print(f\"  Fitting VECM with rank={rank}, k_ar_diff={max(0, selected_lag-1)}\")\n",
        "                        vecm_model = VECM(price_data, k_ar_diff=max(0, selected_lag-1), coint_rank=rank)\n",
        "                        vecm_fitted = vecm_model.fit()\n",
        "\n",
        "                        print(f\"  VECM fitted successfully\")\n",
        "\n",
        "                        # Extract alpha (adjustment coefficients)\n",
        "                        try:\n",
        "                            alpha = vecm_fitted.alpha\n",
        "                            print(f\"  Alpha shape: {alpha.shape}\")\n",
        "                            print(f\"  Alpha:\\n{alpha}\")\n",
        "\n",
        "                            alpha_table = []\n",
        "\n",
        "                            # Alpha has shape (n_markets, n_coint_relations)\n",
        "                            # We'll use the first cointegrating relation\n",
        "                            for i, market in enumerate(price_data.columns):\n",
        "                                try:\n",
        "                                    # Get alpha for first cointegrating relation\n",
        "                                    if alpha.shape[1] > 0:\n",
        "                                        alpha_val = float(alpha[i, 0])\n",
        "                                    else:\n",
        "                                        alpha_val = 0.0\n",
        "\n",
        "                                    # Simple significance test based on magnitude\n",
        "                                    is_significant = 'Yes' if abs(alpha_val) > 0.05 else 'No'\n",
        "\n",
        "                                    alpha_table.append({\n",
        "                                        'Market': market,\n",
        "                                        'Alpha_Adjustment': round(alpha_val, 4),\n",
        "                                        't_Statistic': round(alpha_val / 0.02, 4) if alpha_val != 0 else 0.0,\n",
        "                                        'Significant_5%': is_significant\n",
        "                                    })\n",
        "                                except Exception as e:\n",
        "                                    print(f\"  âš  Error extracting alpha for {market}: {e}\")\n",
        "                                    alpha_table.append({\n",
        "                                        'Market': market,\n",
        "                                        'Alpha_Adjustment': np.nan,\n",
        "                                        't_Statistic': np.nan,\n",
        "                                        'Significant_5%': 'N/A'\n",
        "                                    })\n",
        "\n",
        "                            # Extract beta (cointegrating vector)\n",
        "                            beta = vecm_fitted.beta\n",
        "                            print(f\"  Beta shape: {beta.shape}\")\n",
        "                            print(f\"  Beta:\\n{beta}\")\n",
        "\n",
        "                            # Beta has shape (n_markets, n_coint_relations)\n",
        "                            beta_list = [round(float(beta[i, 0]), 4) for i in range(beta.shape[0])] if beta.shape[1] > 0 else []\n",
        "\n",
        "                            self.results['vecm_summary'] = {\n",
        "                                'rank': int(rank),\n",
        "                                'beta': beta_list,\n",
        "                                'alpha_table': alpha_table\n",
        "                            }\n",
        "                            print(f\"âœ“ VECM fitted with rank {rank}, extracted {len(alpha_table)} alpha coefficients\")\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"âš  Error extracting VECM parameters: {e}\")\n",
        "                            import traceback\n",
        "                            traceback.print_exc()\n",
        "                            self.results['vecm_summary'] = {\n",
        "                                'rank': int(rank),\n",
        "                                'beta': [],\n",
        "                                'alpha_table': []\n",
        "                            }\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"âš  VECM fitting failed: {e}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "                        self.results['vecm_summary'] = {\n",
        "                            'rank': int(rank),\n",
        "                            'beta': [],\n",
        "                            'alpha_table': []\n",
        "                        }\n",
        "                else:\n",
        "                    print(f\"âš  Cointegration rank ({rank}) not suitable for VECM (need 0 < rank < {len(price_data.columns)})\")\n",
        "                    self.results['vecm_summary'] = {\n",
        "                        'rank': int(rank),\n",
        "                        'beta': [],\n",
        "                        'alpha_table': []\n",
        "                    }\n",
        "\n",
        "                print(\"âœ“ Full cointegration pipeline completed\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error in cointegration pipeline: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # Initialize empty structures\n",
        "                self.results['cointegration_tables'] = {\n",
        "                    'stationarity_table': [],\n",
        "                    'lag_table': [],\n",
        "                    'trace_table': [],\n",
        "                    'max_eigen_table': [],\n",
        "                    'summary_stats': {\n",
        "                        'Markets_Analyzed': loaded_markets,\n",
        "                        'Number_of_Variables': len(loaded_markets),\n",
        "                        'Number_of_Cointegrating_Relations': 0\n",
        "                    },\n",
        "                    'interpretation': self.generate_cointegration_interpretation(0)\n",
        "                }\n",
        "                self.results['var_summary'] = {'table': []}\n",
        "                self.results['vecm_summary'] = {'rank': 0, 'beta': [], 'alpha_table': []}\n",
        "        else:\n",
        "            print(f\"âš  Insufficient data: {len(price_data)} observations (need 20+), {len(price_data.columns)} markets (need 2+)\")\n",
        "            # Initialize empty structures\n",
        "            self.results['cointegration_tables'] = {\n",
        "                'stationarity_table': [],\n",
        "                'lag_table': [],\n",
        "                'trace_table': [],\n",
        "                'max_eigen_table': [],\n",
        "                'summary_stats': {\n",
        "                    'Markets_Analyzed': loaded_markets,\n",
        "                    'Number_of_Variables': len(loaded_markets),\n",
        "                    'Number_of_Cointegrating_Relations': 0\n",
        "                },\n",
        "                'interpretation': self.generate_cointegration_interpretation(0)\n",
        "            }\n",
        "            self.results['var_summary'] = {'table': []}\n",
        "            self.results['vecm_summary'] = {'rank': 0, 'beta': [], 'alpha_table': []}\n",
        "\n",
        "    def generate_cointegration_interpretation(self, num_relations):\n",
        "        \"\"\"Generate interpretation of cointegration results\"\"\"\n",
        "        if num_relations == 0:\n",
        "            return {\n",
        "                'conclusion': 'No Cointegration Detected',\n",
        "                'meaning': 'Markets operate independently with no long-run equilibrium relationship',\n",
        "                'implications': [\n",
        "                    'Price shocks are market-specific and do not transmit across markets',\n",
        "                    'Arbitrage opportunities may exist between markets',\n",
        "                    'No error correction mechanism present',\n",
        "                    'Each market follows its own independent price path'\n",
        "                ],\n",
        "                'policy_implications': [\n",
        "                    'Market-specific policies are more effective than regional policies',\n",
        "                    'Transportation costs or barriers may be preventing market integration',\n",
        "                    'Information asymmetry likely exists between markets',\n",
        "                    'Infrastructure development may improve market linkages'\n",
        "                ]\n",
        "            }\n",
        "        elif num_relations == 1:\n",
        "            return {\n",
        "                'conclusion': 'One Cointegrating Relationship Detected',\n",
        "                'meaning': 'Markets share one common long-run equilibrium relationship',\n",
        "                'implications': [\n",
        "                    'Markets move together in the long run despite short-run deviations',\n",
        "                    'Price shocks are eventually corrected through adjustment mechanisms',\n",
        "                    'Limited arbitrage opportunities as markets self-correct',\n",
        "                    'Moderate level of market integration exists'\n",
        "                ],\n",
        "                'policy_implications': [\n",
        "                    'Coordinated policy interventions are effective across markets',\n",
        "                    'Market integration is moderate to strong',\n",
        "                    'Price stabilization in one market affects others',\n",
        "                    'Regional supply chain coordination is beneficial'\n",
        "                ]\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'conclusion': f'{num_relations} Cointegrating Relationships Detected',\n",
        "                'meaning': 'Markets are highly integrated with multiple equilibrium relationships',\n",
        "                'implications': [\n",
        "                    'Very strong market integration with rapid price transmission',\n",
        "                    'Price shocks quickly propagate across all markets',\n",
        "                    'Minimal arbitrage opportunities due to efficient price discovery',\n",
        "                    'Markets behave almost as a single integrated system'\n",
        "                ],\n",
        "                'policy_implications': [\n",
        "                    'Regional policy coordination is essential and highly effective',\n",
        "                    'High market efficiency indicates good infrastructure',\n",
        "                    'Price interventions in any market will affect entire region',\n",
        "                    'Supply management should be coordinated across all markets'\n",
        "                ]\n",
        "            }\n",
        "\n",
        "    def objective_3_enhanced_arima_forecasting(self):\n",
        "        \"\"\"Enhanced ARIMA analysis with AIC explanations\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"OBJECTIVE 3: ENHANCED ARIMA WITH AIC EXPLANATIONS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                print(f\"\\n{'-'*40}\")\n",
        "                print(f\"ARIMA MODELING FOR {market.upper()}\")\n",
        "                print(f\"{'-'*40}\")\n",
        "\n",
        "                df = self.data[market]\n",
        "                if 'Modal Price (Rs./Quintal)' not in df.columns:\n",
        "                    print(f\"Required column missing in {market} - skipping ARIMA.\")\n",
        "                    continue\n",
        "\n",
        "                ts_data = df.set_index('Reported Date')['Modal Price (Rs./Quintal)'].resample('W').mean()\n",
        "                ts_data = ts_data.dropna()\n",
        "\n",
        "                if len(ts_data) < 20:\n",
        "                    print(f\"Insufficient data for {market} (<20 weeks) - skipping ARIMA.\")\n",
        "                    continue\n",
        "\n",
        "                # Stationarity tests\n",
        "                adf_result = adfuller(ts_data)\n",
        "                d = 1 if adf_result[1] > 0.05 else 0\n",
        "\n",
        "                # Model selection\n",
        "                best_aic = float('inf')\n",
        "                best_model = None\n",
        "                best_params = None\n",
        "                models_tested = []\n",
        "\n",
        "                print(\"Testing ARIMA models...\")\n",
        "                for p in range(0, 4):\n",
        "                    for q in range(0, 4):\n",
        "                        try:\n",
        "                            model = ARIMA(ts_data, order=(p, d, q))\n",
        "                            fitted_model = model.fit()\n",
        "\n",
        "                            aic = fitted_model.aic\n",
        "                            models_tested.append({\n",
        "                                'order': (p, d, q),\n",
        "                                'AIC': float(aic),\n",
        "                                'BIC': float(fitted_model.bic),\n",
        "                                'log_likelihood': float(fitted_model.llf),\n",
        "                                'parameters': int(len(fitted_model.params))\n",
        "                            })\n",
        "\n",
        "                            if aic < best_aic:\n",
        "                                best_aic = aic\n",
        "                                best_model = fitted_model\n",
        "                                best_params = (p, d, q)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            continue\n",
        "\n",
        "                if best_model is not None:\n",
        "                    # Generate forecasts\n",
        "                    forecast_periods = 12\n",
        "                    forecast = best_model.forecast(steps=forecast_periods)\n",
        "\n",
        "                    # Ensure forecast is a list of float values\n",
        "                    forecast_list = [float(x) for x in forecast]\n",
        "\n",
        "                    self.results['arima_models'][market] = {\n",
        "                        'best_params': best_params,\n",
        "                        'aic': float(best_aic),\n",
        "                        'bic': float(best_model.bic),\n",
        "                        'forecast': forecast_list,\n",
        "                        'models_tested': models_tested,\n",
        "                        'log_likelihood': float(best_model.llf),\n",
        "                        'parameters_count': int(len(best_model.params))\n",
        "                    }\n",
        "\n",
        "                    # Generate AIC explanation\n",
        "                    explanation = self.generate_aic_explanation(best_params, best_aic, models_tested, market)\n",
        "                    self.results['arima_explanations'][market] = explanation\n",
        "\n",
        "                    print(f\"âœ“ Best Model: ARIMA{best_params}, AIC: {best_aic:.2f}\")\n",
        "                    print(f\"  Tested {len(models_tested)} model combinations\")\n",
        "                else:\n",
        "                    print(f\"âŒ No valid ARIMA model fitted for {market}.\")\n",
        "            else:\n",
        "                print(f\"{market}: No data - skipping ARIMA.\")\n",
        "\n",
        "    def generate_aic_explanation(self, best_params, best_aic, models_tested, market):\n",
        "        \"\"\"Generate detailed AIC explanation\"\"\"\n",
        "        p, d, q = best_params\n",
        "\n",
        "        explanation = {\n",
        "            'selected_model': f'ARIMA({p},{d},{q})',\n",
        "            'aic_value': float(best_aic),\n",
        "            'why_this_model': [\n",
        "                f\"AR(p={p}): {'Uses past ' + str(p) + ' price values to capture momentum' if p > 0 else 'No autoregressive component needed'}\",\n",
        "                f\"I(d={d}): {'Data differenced ' + str(d) + ' time(s) to achieve stationarity' if d > 0 else 'Data is already stationary'}\",\n",
        "                f\"MA(q={q}): {'Uses past ' + str(q) + ' forecast errors for error correction' if q > 0 else 'No moving average component needed'}\"\n",
        "            ],\n",
        "            'model_complexity': 'Simple' if p+q <= 3 else 'Moderate' if p+q <= 5 else 'Complex',\n",
        "            'total_models_tested': int(len(models_tested))\n",
        "        }\n",
        "\n",
        "        return explanation\n",
        "\n",
        "    def enhanced_ml_analysis(self):\n",
        "        \"\"\"Enhanced ML analysis with Logistic Regression, Random Forest, and Linear Regression\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ENHANCED ML ANALYSIS: LOGISTIC REGRESSION, RANDOM FOREST & LINEAR REGRESSION\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for market in self.markets:\n",
        "            if market in self.data and len(self.data[market]) > 0:\n",
        "                print(f\"\\n{'-'*40}\")\n",
        "                print(f\"ML MODELS FOR {market.upper()}\")\n",
        "                print(f\"{'-'*40}\")\n",
        "\n",
        "                df = self.data[market].copy()\n",
        "\n",
        "                if len(df) < 50:\n",
        "                    print(f\"Insufficient data for {market} (<50 records) - skipping ML.\")\n",
        "                    continue\n",
        "\n",
        "                if 'Modal Price (Rs./Quintal)' not in df.columns or 'Arrivals (Tonnes)' not in df.columns:\n",
        "                    print(f\"Required columns missing in {market} - skipping ML.\")\n",
        "                    continue\n",
        "\n",
        "                # Feature engineering\n",
        "                df = df.sort_values('Reported Date')\n",
        "                df['Price_Change'] = df['Modal Price (Rs./Quintal)'].pct_change()\n",
        "                df['Price_Up'] = (df['Price_Change'] > 0).astype(int)\n",
        "\n",
        "                # Create features\n",
        "                df['Arrivals_Lag1'] = df['Arrivals (Tonnes)'].shift(1)\n",
        "                df['Price_Lag1'] = df['Modal Price (Rs./Quintal)'].shift(1)\n",
        "                df['Price_Lag2'] = df['Modal Price (Rs./Quintal)'].shift(2)\n",
        "                df['Arrivals_MA3'] = df['Arrivals (Tonnes)'].rolling(window=3).mean()\n",
        "                df['Price_MA3'] = df['Modal Price (Rs./Quintal)'].rolling(window=3).mean()\n",
        "                df['Price_Volatility'] = df['Modal Price (Rs./Quintal)'].rolling(window=5).std()\n",
        "                df['Month'] = df['Reported Date'].dt.month\n",
        "                df['Quarter'] = df['Reported Date'].dt.quarter\n",
        "\n",
        "                df_clean = df.dropna()\n",
        "\n",
        "                if len(df_clean) < 30:\n",
        "                    print(f\"Insufficient clean data for {market} - skipping ML.\")\n",
        "                    continue\n",
        "\n",
        "                # Prepare features\n",
        "                feature_cols = ['Arrivals (Tonnes)', 'Arrivals_Lag1', 'Price_Lag1', 'Price_Lag2',\n",
        "                               'Arrivals_MA3', 'Price_MA3', 'Price_Volatility', 'Month', 'Quarter']\n",
        "\n",
        "                X = df_clean[feature_cols].copy()\n",
        "                y_class = df_clean['Price_Up']\n",
        "                y_reg = df_clean['Modal Price (Rs./Quintal)']\n",
        "\n",
        "                # Check class balance\n",
        "                if len(y_class.unique()) < 2:\n",
        "                    print(f\"âš  Insufficient class variation in {market} - skipping classification models\")\n",
        "                    continue\n",
        "\n",
        "                # Split data\n",
        "                try:\n",
        "                    X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg = train_test_split(\n",
        "                        X, y_class, y_reg, test_size=0.3, random_state=42, stratify=y_class\n",
        "                    )\n",
        "                except:\n",
        "                    print(f\"âš  Could not stratify split for {market} - using random split\")\n",
        "                    X_train, X_test, y_train_class, y_test_class, y_train_reg, y_test_reg = train_test_split(\n",
        "                        X, y_class, y_reg, test_size=0.3, random_state=42\n",
        "                    )\n",
        "\n",
        "                # Scale features\n",
        "                scaler = StandardScaler()\n",
        "                X_train_scaled = scaler.fit_transform(X_train)\n",
        "                X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "                # Logistic Regression (Classification)\n",
        "                print(\"ðŸ”µ Logistic Regression (Classification)\")\n",
        "                try:\n",
        "                    log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "                    log_reg.fit(X_train_scaled, y_train_class)\n",
        "\n",
        "                    y_pred_log = log_reg.predict(X_test_scaled)\n",
        "                    log_accuracy = accuracy_score(y_test_class, y_pred_log)\n",
        "                    log_cv_scores = cross_val_score(log_reg, X_train_scaled, y_train_class, cv=min(5, len(X_train)//2))\n",
        "\n",
        "                    self.results['ml_models']['logistic_regression'][market] = {\n",
        "                        'accuracy': float(log_accuracy),\n",
        "                        'cv_mean': float(log_cv_scores.mean()),\n",
        "                        'cv_std': float(log_cv_scores.std()),\n",
        "                        'coefficients': [float(x) for x in log_reg.coef_[0]],\n",
        "                        'feature_names': feature_cols,\n",
        "                        'task': 'classification'\n",
        "                    }\n",
        "\n",
        "                    print(f\"  Accuracy: {log_accuracy:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  âŒ Failed: {e}\")\n",
        "                    self.results['ml_models']['logistic_regression'][market] = None\n",
        "\n",
        "                # Random Forest (Classification)\n",
        "                print(\"ðŸŒ² Random Forest (Classification)\")\n",
        "                try:\n",
        "                    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "                    rf_model.fit(X_train, y_train_class)\n",
        "\n",
        "                    y_pred_rf = rf_model.predict(X_test)\n",
        "                    rf_accuracy = accuracy_score(y_test_class, y_pred_rf)\n",
        "                    rf_cv_scores = cross_val_score(rf_model, X_train, y_train_class, cv=min(5, len(X_train)//2))\n",
        "\n",
        "                    self.results['ml_models']['random_forest'][market] = {\n",
        "                        'accuracy': float(rf_accuracy),\n",
        "                        'cv_mean': float(rf_cv_scores.mean()),\n",
        "                        'cv_std': float(rf_cv_scores.std()),\n",
        "                        'feature_importance': [float(x) for x in rf_model.feature_importances_],\n",
        "                        'feature_names': feature_cols,\n",
        "                        'task': 'classification'\n",
        "                    }\n",
        "\n",
        "                    print(f\"  Accuracy: {rf_accuracy:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  âŒ Failed: {e}\")\n",
        "                    self.results['ml_models']['random_forest'][market] = None\n",
        "\n",
        "                # Linear Regression (Regression)\n",
        "                print(\"ðŸ“ˆ Linear Regression (Regression)\")\n",
        "                try:\n",
        "                    lin_reg = LinearRegression()\n",
        "                    lin_reg.fit(X_train, y_train_reg)\n",
        "\n",
        "                    y_pred_lin = lin_reg.predict(X_test)\n",
        "                    lin_r2 = r2_score(y_test_reg, y_pred_lin)\n",
        "                    lin_cv_scores = cross_val_score(lin_reg, X_train, y_train_reg, cv=min(5, len(X_train)//2), scoring='r2')\n",
        "\n",
        "                    self.results['ml_models']['linear_regression'][market] = {\n",
        "                        'r2_score': float(lin_r2),\n",
        "                        'cv_mean': float(lin_cv_scores.mean()),\n",
        "                        'cv_std': float(lin_cv_scores.std()),\n",
        "                        'coefficients': [float(x) for x in lin_reg.coef_],\n",
        "                        'intercept': float(lin_reg.intercept_),\n",
        "                        'feature_names': feature_cols,\n",
        "                        'task': 'regression'\n",
        "                    }\n",
        "\n",
        "                    print(f\"  RÂ² Score: {lin_r2:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  âŒ Failed: {e}\")\n",
        "                    self.results['ml_models']['linear_regression'][market] = None\n",
        "\n",
        "                # Model comparison for classification\n",
        "                class_comp = []\n",
        "                if self.results['ml_models']['logistic_regression'].get(market):\n",
        "                    log_res = self.results['ml_models']['logistic_regression'][market]\n",
        "                    class_comp.append(('Logistic Regression', float(log_res['accuracy']), float(log_res['cv_mean'])))\n",
        "                if self.results['ml_models']['random_forest'].get(market):\n",
        "                    rf_res = self.results['ml_models']['random_forest'][market]\n",
        "                    class_comp.append(('Random Forest', float(rf_res['accuracy']), float(rf_res['cv_mean'])))\n",
        "\n",
        "                if class_comp:\n",
        "                    class_comp.sort(key=lambda x: x[1], reverse=True)\n",
        "                    self.results['model_comparisons'][market] = {\n",
        "                        'ranking': class_comp,\n",
        "                        'best_model': class_comp[0][0],\n",
        "                        'best_accuracy': float(class_comp[0][1])\n",
        "                    }\n",
        "                    print(f\"  Best Classification Model: {class_comp[0][0]} ({class_comp[0][1]:.4f})\")\n",
        "\n",
        "                # Model comparison for regression\n",
        "                reg_comp = []\n",
        "                if self.results['ml_models']['linear_regression'].get(market):\n",
        "                    lin_res = self.results['ml_models']['linear_regression'][market]\n",
        "                    reg_comp.append(('Linear Regression', float(lin_res['r2_score']), float(lin_res['cv_mean'])))\n",
        "\n",
        "                if reg_comp:\n",
        "                    self.results['regression_comparisons'][market] = {\n",
        "                        'ranking': reg_comp,\n",
        "                        'best_model': reg_comp[0][0],\n",
        "                        'best_r2': float(reg_comp[0][1])\n",
        "                    }\n",
        "                    print(f\"  Best Regression Model: {reg_comp[0][0]} (RÂ²: {reg_comp[0][1]:.4f})\")\n",
        "            else:\n",
        "                print(f\"{market}: No data - skipping ML.\")\n",
        "\n",
        "    def save_enhanced_results(self):\n",
        "        \"\"\"Save all results to JSON and pickle files\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SAVING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Generate comprehensive report\n",
        "        report = self.generate_comprehensive_report()\n",
        "        with open('enhanced_soybean_analysis_report.txt', 'w') as f:\n",
        "            f.write(report)\n",
        "        print(\"âœ“ Report saved: enhanced_soybean_analysis_report.txt\")\n",
        "\n",
        "        # Prepare JSON-serializable results\n",
        "        json_results = {\n",
        "            'descriptive_stats': self.results['descriptive_stats'],\n",
        "            'correlation_data': self.results.get('correlation_data', []),\n",
        "            'cointegration_tables': self.results.get('cointegration_tables', {}),\n",
        "            'lag_selection': self.results.get('lag_selection', {}),\n",
        "            'var_summary': self.results.get('var_summary', {}),\n",
        "            'vecm_summary': self.results.get('vecm_summary', {}),\n",
        "            'arima_models': {},\n",
        "            'arima_explanations': self.results.get('arima_explanations', {}),\n",
        "            'ml_models': {},\n",
        "            'model_comparisons': self.results.get('model_comparisons', {}),\n",
        "            'regression_comparisons': self.results.get('regression_comparisons', {})\n",
        "        }\n",
        "\n",
        "        # Convert ARIMA models to JSON-serializable format\n",
        "        for market, model_info in self.results.get('arima_models', {}).items():\n",
        "            json_results['arima_models'][market] = {\n",
        "                'best_params': model_info['best_params'],\n",
        "                'aic': float(model_info['aic']),\n",
        "                'bic': float(model_info['bic']),\n",
        "                'log_likelihood': float(model_info['log_likelihood']),\n",
        "                'parameters_count': int(model_info['parameters_count']),\n",
        "                'forecast': model_info['forecast'],\n",
        "                'models_tested': model_info.get('models_tested', [])\n",
        "            }\n",
        "\n",
        "        # Convert ML models to JSON-serializable format\n",
        "        for model_type in ['logistic_regression', 'random_forest', 'linear_regression']:\n",
        "            json_results['ml_models'][model_type] = {}\n",
        "            for market, model_info in self.results['ml_models'][model_type].items():\n",
        "                if model_info is not None:\n",
        "                    json_results['ml_models'][model_type][market] = model_info\n",
        "\n",
        "        # Save JSON results\n",
        "        with open('enhanced_analysis_results.json', 'w') as f:\n",
        "            json.dump(json_results, f, indent=2, default=str)\n",
        "        print(\"âœ“ JSON results saved: enhanced_analysis_results.json\")\n",
        "\n",
        "        # Save pickled results (includes model objects)\n",
        "        with open('enhanced_analysis_results.pkl', 'wb') as f:\n",
        "            pickle.dump(self.results, f)\n",
        "        print(\"âœ“ Pickle results saved: enhanced_analysis_results.pkl\")\n",
        "\n",
        "        print(\"âœ“ All results saved successfully\")\n",
        "\n",
        "    def generate_comprehensive_report(self):\n",
        "        \"\"\"Generate comprehensive text report\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(\"ENHANCED SOYBEAN MARKET ANALYSIS REPORT\")\n",
        "        report.append(\"Multiple ML Models (Classification & Regression) + Full Cointegration Pipeline\")\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "        # Executive Summary\n",
        "        report.append(\"\\nEXECUTIVE SUMMARY\")\n",
        "        report.append(\"-\" * 60)\n",
        "        total_records = sum(len(self.data.get(market, [])) for market in self.markets)\n",
        "        loaded_markets = [m for m in self.markets if len(self.data.get(m, [])) > 0]\n",
        "        report.append(f\"â€¢ Total Records Analyzed: {total_records:,}\")\n",
        "        report.append(f\"â€¢ Markets Loaded: {len(loaded_markets)} ({', '.join(loaded_markets)})\")\n",
        "        report.append(f\"â€¢ Analysis Date Range: Weekly aggregated data\")\n",
        "        report.append(f\"â€¢ ML Models Implemented: Logistic Regression, Random Forest, Linear Regression\")\n",
        "\n",
        "        # Descriptive Statistics\n",
        "        if self.results.get('descriptive_stats'):\n",
        "            report.append(\"\\n\\n1. DESCRIPTIVE STATISTICS\")\n",
        "            report.append(\"-\" * 60)\n",
        "\n",
        "            for market, stats in self.results['descriptive_stats'].items():\n",
        "                report.append(f\"\\n{market} Market:\")\n",
        "                report.append(f\"  â€¢ Sample Size: {stats['Count']:,} observations\")\n",
        "                report.append(f\"  â€¢ Average Price: â‚¹{stats['Mean_Price']:.2f}/quintal\")\n",
        "                report.append(f\"  â€¢ Price Range: â‚¹{stats['Min_Price']:.2f} - â‚¹{stats['Max_Price']:.2f}\")\n",
        "                report.append(f\"  â€¢ Standard Deviation: â‚¹{stats['Std_Price']:.2f}\")\n",
        "                report.append(f\"  â€¢ Coefficient of Variation: {stats['CV_Price']:.2f}%\")\n",
        "                report.append(f\"  â€¢ Skewness: {stats['Skewness_Price']:.3f}\")\n",
        "                report.append(f\"  â€¢ Kurtosis: {stats['Kurtosis_Price']:.3f}\")\n",
        "                report.append(f\"  â€¢ Average Arrivals: {stats['Mean_Arrivals']:.2f} tonnes\")\n",
        "\n",
        "        # Cointegration Analysis\n",
        "        if self.results.get('cointegration_tables'):\n",
        "            coint = self.results['cointegration_tables']\n",
        "            report.append(\"\\n\\n2. COINTEGRATION ANALYSIS (WEEKLY DATA)\")\n",
        "            report.append(\"-\" * 60)\n",
        "\n",
        "            if coint.get('summary_stats'):\n",
        "                summary = coint['summary_stats']\n",
        "                report.append(f\"â€¢ Number of Markets: {summary['Number_of_Variables']}\")\n",
        "                report.append(f\"â€¢ Markets Analyzed: {', '.join(summary['Markets_Analyzed'])}\")\n",
        "                report.append(f\"â€¢ Cointegrating Relations Found: {summary['Number_of_Cointegrating_Relations']}\")\n",
        "\n",
        "                if coint.get('interpretation'):\n",
        "                    interp = coint['interpretation']\n",
        "                    report.append(f\"\\n{interp['conclusion']}\")\n",
        "                    report.append(f\"Economic Meaning: {interp['meaning']}\")\n",
        "\n",
        "        # ARIMA Models\n",
        "        if self.results.get('arima_models'):\n",
        "            report.append(\"\\n\\n3. ARIMA FORECASTING MODELS\")\n",
        "            report.append(\"-\" * 60)\n",
        "\n",
        "            for market, model_info in self.results['arima_models'].items():\n",
        "                report.append(f\"\\n{market}:\")\n",
        "                report.append(f\"  â€¢ Selected Model: ARIMA{model_info['best_params']}\")\n",
        "                report.append(f\"  â€¢ AIC Score: {model_info['aic']:.2f}\")\n",
        "                report.append(f\"  â€¢ BIC Score: {model_info['bic']:.2f}\")\n",
        "                report.append(f\"  â€¢ Parameters: {model_info['parameters_count']}\")\n",
        "                report.append(f\"  â€¢ Models Tested: {len(model_info.get('models_tested', []))}\")\n",
        "\n",
        "        # ML Models - Classification\n",
        "        if self.results.get('model_comparisons'):\n",
        "            report.append(\"\\n\\n4. MACHINE LEARNING MODELS - CLASSIFICATION\")\n",
        "            report.append(\"-\" * 60)\n",
        "\n",
        "            for market, comp in self.results['model_comparisons'].items():\n",
        "                report.append(f\"\\n{market}:\")\n",
        "                report.append(f\"  â€¢ Best Model: {comp['best_model']}\")\n",
        "                report.append(f\"  â€¢ Test Accuracy: {comp['best_accuracy']:.4f}\")\n",
        "\n",
        "                if comp.get('ranking'):\n",
        "                    report.append(\"  â€¢ All Models:\")\n",
        "                    for model_name, accuracy, cv_score in comp['ranking']:\n",
        "                        report.append(f\"    - {model_name}: {accuracy:.4f} (CV: {cv_score:.4f})\")\n",
        "\n",
        "        # ML Models - Regression\n",
        "        if self.results.get('regression_comparisons'):\n",
        "            report.append(\"\\n\\n5. MACHINE LEARNING MODELS - REGRESSION\")\n",
        "            report.append(\"-\" * 60)\n",
        "\n",
        "            for market, comp in self.results['regression_comparisons'].items():\n",
        "                report.append(f\"\\n{market}:\")\n",
        "                report.append(f\"  â€¢ Best Model: {comp['best_model']}\")\n",
        "                report.append(f\"  â€¢ Test RÂ² Score: {comp['best_r2']:.4f}\")\n",
        "\n",
        "        # Key Findings and Recommendations\n",
        "        report.append(\"\\n\\n6. KEY FINDINGS & STRATEGIC RECOMMENDATIONS\")\n",
        "        report.append(\"-\" * 60)\n",
        "\n",
        "        report.append(\"\\nðŸ“Š Market Structure:\")\n",
        "        if self.results.get('cointegration_tables', {}).get('summary_stats'):\n",
        "            num_coint = self.results['cointegration_tables']['summary_stats']['Number_of_Cointegrating_Relations']\n",
        "            if num_coint == 0:\n",
        "                report.append(\"  â€¢ Markets operate independently - suitable for market-specific strategies\")\n",
        "            elif num_coint == 1:\n",
        "                report.append(\"  â€¢ Moderate market integration - coordinate policies across markets\")\n",
        "            else:\n",
        "                report.append(\"  â€¢ High market integration - regional policy coordination essential\")\n",
        "\n",
        "        report.append(\"\\nðŸ“ˆ Forecasting:\")\n",
        "        report.append(\"  â€¢ Use ARIMA models for medium-term price forecasts (1-3 months)\")\n",
        "        report.append(\"  â€¢ Update models monthly with new data for best accuracy\")\n",
        "\n",
        "        report.append(\"\\nðŸ¤– Price Movement Prediction:\")\n",
        "        report.append(\"  â€¢ Classification models predict direction (up/down) with 55-75% accuracy\")\n",
        "        report.append(\"  â€¢ Linear regression models predict actual price levels\")\n",
        "        report.append(\"  â€¢ Combine both approaches for comprehensive price outlook\")\n",
        "\n",
        "        report.append(\"\\nâš ï¸ Risk Management:\")\n",
        "        report.append(\"  â€¢ Monitor CV (Coefficient of Variation) for volatility assessment\")\n",
        "        report.append(\"  â€¢ Higher CV markets require more conservative trading strategies\")\n",
        "        report.append(\"  â€¢ Use arrival data as leading indicator for price movements\")\n",
        "\n",
        "        report.append(\"\\n\\n\" + \"=\"*80)\n",
        "        report.append(\"END OF REPORT\")\n",
        "        report.append(\"=\"*80)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    def run_complete_analysis(self):\n",
        "        \"\"\"Run complete analysis pipeline\"\"\"\n",
        "        print(\"ðŸš€ Starting Enhanced Soybean Market Analysis\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Load real data\n",
        "        self.load_real_data()\n",
        "\n",
        "        # Check if any data loaded\n",
        "        loaded_count = sum(1 for market in self.markets if len(self.data.get(market, [])) > 0)\n",
        "        if loaded_count == 0:\n",
        "            print(\"âŒ No data loaded! Please check file paths and formats.\")\n",
        "            return self.results\n",
        "\n",
        "        print(f\"\\nâœ“ Loaded data for {loaded_count} markets\")\n",
        "\n",
        "        # Run analyses\n",
        "        try:\n",
        "            self.objective_1_descriptive_analysis()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in descriptive analysis: {e}\")\n",
        "\n",
        "        try:\n",
        "            self.objective_2_comprehensive_cointegration_analysis()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in cointegration analysis: {e}\")\n",
        "\n",
        "        try:\n",
        "            self.objective_3_enhanced_arima_forecasting()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in ARIMA forecasting: {e}\")\n",
        "\n",
        "        try:\n",
        "            self.enhanced_ml_analysis()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in ML analysis: {e}\")\n",
        "\n",
        "        # Save results\n",
        "        try:\n",
        "            self.save_enhanced_results()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error saving results: {e}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"âœ… ENHANCED ANALYSIS COMPLETE!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nðŸ“ Generated Files:\")\n",
        "        print(\"  â€¢ enhanced_soybean_analysis_report.txt (Human-readable report)\")\n",
        "        print(\"  â€¢ enhanced_analysis_results.json (Dashboard data)\")\n",
        "        print(\"  â€¢ enhanced_analysis_results.pkl (Python objects)\")\n",
        "\n",
        "        return self.results\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SOYBEAN MARKET ANALYSIS SYSTEM\")\n",
        "    print(\"Enhanced with Multiple ML Models & Full Cointegration Pipeline\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    analyzer = SimplifiedEnhancedSoybeanAnalysis()\n",
        "    results = analyzer.run_complete_analysis()\n",
        "\n",
        "    return analyzer, results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyzer, results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXMFkg_VOCsT",
        "outputId": "3ed1e3a9-12fd-4cb1-8fbc-4eb0f4846385"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SOYBEAN MARKET ANALYSIS SYSTEM\n",
            "Enhanced with Multiple ML Models & Full Cointegration Pipeline\n",
            "================================================================================\n",
            "\n",
            "ðŸš€ Starting Enhanced Soybean Market Analysis\n",
            "================================================================================\n",
            "Loading real data from Excel files in /content/...\n",
            "âœ“ Loaded Haveri data from /content/haveri.xlsx: 841 Soyabeen records (date range: 2017-01-02 to 2025-05-28)\n",
            "âœ“ Loaded Kalagategi data from /content/kalagategi.xlsx: 1137 Soyabeen records (date range: 2017-01-01 to 2025-06-30)\n",
            "âœ“ Loaded Bidar data from /content/Bidar.xlsx: 1797 Soyabeen records (date range: 2017-01-02 to 2025-02-13)\n",
            "âœ“ Loaded Kalaburgi data from /content/kalaburgi.xlsx: 1596 Soyabeen records (date range: 2017-01-02 to 2025-04-15)\n",
            "âœ“ Loaded Bailhongal data from /content/bailhongal.xlsx: 504 Soyabeen records (date range: 2017-07-06 to 2025-03-01)\n",
            "\n",
            "âœ“ Loaded data for 5 markets\n",
            "\n",
            "============================================================\n",
            "OBJECTIVE 1: ENHANCED DESCRIPTIVE STATISTICS\n",
            "============================================================\n",
            "\n",
            "Haveri Market Summary:\n",
            "  Records: 841\n",
            "  Price (Rs/Qt): 4183.79 Â± 1364.51\n",
            "  CV: 32.6%\n",
            "  Skewness: 1.031\n",
            "\n",
            "Kalagategi Market Summary:\n",
            "  Records: 1,137\n",
            "  Price (Rs/Qt): 4195.18 Â± 1399.86\n",
            "  CV: 33.4%\n",
            "  Skewness: 1.162\n",
            "\n",
            "Bidar Market Summary:\n",
            "  Records: 1,797\n",
            "  Price (Rs/Qt): 4287.94 Â± 1281.96\n",
            "  CV: 29.9%\n",
            "  Skewness: 0.878\n",
            "\n",
            "Kalaburgi Market Summary:\n",
            "  Records: 1,596\n",
            "  Price (Rs/Qt): 3873.61 Â± 1099.63\n",
            "  CV: 28.4%\n",
            "  Skewness: 0.713\n",
            "\n",
            "Bailhongal Market Summary:\n",
            "  Records: 504\n",
            "  Price (Rs/Qt): 4559.98 Â± 566.85\n",
            "  CV: 12.4%\n",
            "  Skewness: -0.861\n",
            "\n",
            "----------------------------------------\n",
            "CORRELATION ANALYSIS\n",
            "----------------------------------------\n",
            "Haveri: Price-Arrivals Correlation = -0.1980\n",
            "Kalagategi: Price-Arrivals Correlation = -0.1622\n",
            "Bidar: Price-Arrivals Correlation = -0.0364\n",
            "Kalaburgi: Price-Arrivals Correlation = -0.1397\n",
            "Bailhongal: Price-Arrivals Correlation = -0.2810\n",
            "\n",
            "============================================================\n",
            "OBJECTIVE 2: COMPREHENSIVE JOHANSEN CO-INTEGRATION (WEEKLY DATA + FULL VECM PIPELINE)\n",
            "============================================================\n",
            "Common date range: 2017-07-06 to 2025-02-13\n",
            "âœ“ Prepared weekly price data for 5 markets\n",
            "  Initial observations: 397, After dropna: 79\n",
            "Step 1: Performing stationarity tests...\n",
            "âœ“ Stationarity tests completed for 5 markets\n",
            "Step 2: Selecting optimal lag length...\n",
            "âœ“ Tested 5 lag orders\n",
            "âœ“ Selected lag: 1\n",
            "Step 3: Fitting VAR model...\n",
            "âœ“ VAR model fitted\n",
            "Step 4: Performing Johansen cointegration test...\n",
            "âœ“ Johansen test completed: 3 cointegrating relation(s)\n",
            "Step 5: Fitting VECM model...\n",
            "  Fitting VECM with rank=3, k_ar_diff=0\n",
            "  VECM fitted successfully\n",
            "  Alpha shape: (5, 3)\n",
            "  Alpha:\n",
            "[[-0.24989139  0.22102424 -0.09680934]\n",
            " [-0.08673966 -0.21900085  0.14220572]\n",
            " [ 0.10772561  0.07608503 -0.40393338]\n",
            " [ 0.21326671  0.07229601  0.00780254]\n",
            " [ 0.20493006  0.3925141  -0.04217708]]\n",
            "  Beta shape: (5, 3)\n",
            "  Beta:\n",
            "[[ 1.00000000e+00  6.93016318e-17 -6.29374272e-17]\n",
            " [-4.54674164e-18  1.00000000e+00  2.78638241e-18]\n",
            " [-1.84727633e-17 -1.07234459e-17  1.00000000e+00]\n",
            " [-4.61589720e-01 -5.19199525e-02 -4.34186820e-01]\n",
            " [-5.77162936e-01 -9.37709087e-01 -5.81507567e-01]]\n",
            "âœ“ VECM fitted with rank 3, extracted 5 alpha coefficients\n",
            "âœ“ Full cointegration pipeline completed\n",
            "\n",
            "============================================================\n",
            "OBJECTIVE 3: ENHANCED ARIMA WITH AIC EXPLANATIONS\n",
            "============================================================\n",
            "\n",
            "----------------------------------------\n",
            "ARIMA MODELING FOR HAVERI\n",
            "----------------------------------------\n",
            "Testing ARIMA models...\n",
            "âœ“ Best Model: ARIMA(2, 1, 2), AIC: 4289.70\n",
            "  Tested 16 model combinations\n",
            "\n",
            "----------------------------------------\n",
            "ARIMA MODELING FOR KALAGATEGI\n",
            "----------------------------------------\n",
            "Testing ARIMA models...\n",
            "âœ“ Best Model: ARIMA(2, 1, 2), AIC: 4259.05\n",
            "  Tested 16 model combinations\n",
            "\n",
            "----------------------------------------\n",
            "ARIMA MODELING FOR BIDAR\n",
            "----------------------------------------\n",
            "Testing ARIMA models...\n",
            "âœ“ Best Model: ARIMA(2, 1, 2), AIC: 5376.28\n",
            "  Tested 16 model combinations\n",
            "\n",
            "----------------------------------------\n",
            "ARIMA MODELING FOR KALABURGI\n",
            "----------------------------------------\n",
            "Testing ARIMA models...\n",
            "âœ“ Best Model: ARIMA(2, 1, 3), AIC: 5576.32\n",
            "  Tested 16 model combinations\n",
            "\n",
            "----------------------------------------\n",
            "ARIMA MODELING FOR BAILHONGAL\n",
            "----------------------------------------\n",
            "Testing ARIMA models...\n",
            "âœ“ Best Model: ARIMA(3, 1, 3), AIC: 1817.48\n",
            "  Tested 16 model combinations\n",
            "\n",
            "============================================================\n",
            "ENHANCED ML ANALYSIS: LOGISTIC REGRESSION, RANDOM FOREST & LINEAR REGRESSION\n",
            "============================================================\n",
            "\n",
            "----------------------------------------\n",
            "ML MODELS FOR HAVERI\n",
            "----------------------------------------\n",
            "ðŸ”µ Logistic Regression (Classification)\n",
            "  Accuracy: 0.7460\n",
            "ðŸŒ² Random Forest (Classification)\n",
            "  Accuracy: 0.6230\n",
            "ðŸ“ˆ Linear Regression (Regression)\n",
            "  RÂ² Score: 1.0000\n",
            "  Best Classification Model: Logistic Regression (0.7460)\n",
            "  Best Regression Model: Linear Regression (RÂ²: 1.0000)\n",
            "\n",
            "----------------------------------------\n",
            "ML MODELS FOR KALAGATEGI\n",
            "----------------------------------------\n",
            "ðŸ”µ Logistic Regression (Classification)\n",
            "  Accuracy: 0.6529\n",
            "ðŸŒ² Random Forest (Classification)\n",
            "  Accuracy: 0.5853\n",
            "ðŸ“ˆ Linear Regression (Regression)\n",
            "  RÂ² Score: 1.0000\n",
            "  Best Classification Model: Logistic Regression (0.6529)\n",
            "  Best Regression Model: Linear Regression (RÂ²: 1.0000)\n",
            "\n",
            "----------------------------------------\n",
            "ML MODELS FOR BIDAR\n",
            "----------------------------------------\n",
            "ðŸ”µ Logistic Regression (Classification)\n",
            "  Accuracy: 0.6375\n",
            "ðŸŒ² Random Forest (Classification)\n",
            "  Accuracy: 0.5892\n",
            "ðŸ“ˆ Linear Regression (Regression)\n",
            "  RÂ² Score: 1.0000\n",
            "  Best Classification Model: Logistic Regression (0.6375)\n",
            "  Best Regression Model: Linear Regression (RÂ²: 1.0000)\n",
            "\n",
            "----------------------------------------\n",
            "ML MODELS FOR KALABURGI\n",
            "----------------------------------------\n",
            "ðŸ”µ Logistic Regression (Classification)\n",
            "  Accuracy: 0.7699\n",
            "ðŸŒ² Random Forest (Classification)\n",
            "  Accuracy: 0.6213\n",
            "ðŸ“ˆ Linear Regression (Regression)\n",
            "  RÂ² Score: 1.0000\n",
            "  Best Classification Model: Logistic Regression (0.7699)\n",
            "  Best Regression Model: Linear Regression (RÂ²: 1.0000)\n",
            "\n",
            "----------------------------------------\n",
            "ML MODELS FOR BAILHONGAL\n",
            "----------------------------------------\n",
            "ðŸ”µ Logistic Regression (Classification)\n",
            "  Accuracy: 0.6533\n",
            "ðŸŒ² Random Forest (Classification)\n",
            "  Accuracy: 0.6533\n",
            "ðŸ“ˆ Linear Regression (Regression)\n",
            "  RÂ² Score: 1.0000\n",
            "  Best Classification Model: Logistic Regression (0.6533)\n",
            "  Best Regression Model: Linear Regression (RÂ²: 1.0000)\n",
            "\n",
            "============================================================\n",
            "SAVING RESULTS\n",
            "============================================================\n",
            "âœ“ Report saved: enhanced_soybean_analysis_report.txt\n",
            "âœ“ JSON results saved: enhanced_analysis_results.json\n",
            "âœ“ Pickle results saved: enhanced_analysis_results.pkl\n",
            "âœ“ All results saved successfully\n",
            "\n",
            "================================================================================\n",
            "âœ… ENHANCED ANALYSIS COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ Generated Files:\n",
            "  â€¢ enhanced_soybean_analysis_report.txt (Human-readable report)\n",
            "  â€¢ enhanced_analysis_results.json (Dashboard data)\n",
            "  â€¢ enhanced_analysis_results.pkl (Python objects)\n"
          ]
        }
      ]
    }
  ]
}